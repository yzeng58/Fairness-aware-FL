{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, copy, time, itertools, random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from load_adult import *\n",
    "from utils import *\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(option, logits, targets, distance, sensitive, mean_sensitive, larg = 1):\n",
    "    acc_loss = F.cross_entropy(logits, targets, reduction = 'sum')\n",
    "    fair_loss = torch.mul(sensitive - sensitive.type(torch.FloatTensor).mean(), distance.T[0])\n",
    "    fair_loss = torch.mean(torch.mul(fair_loss, fair_loss)) # modified mean to sum\n",
    "    if option == 'Zafar':\n",
    "        return acc_loss + larg*fair_loss, acc_loss, larg*fair_loss\n",
    "    else:\n",
    "        return acc_loss, acc_loss, larg*fair_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairBatch(Sampler):\n",
    "    \"\"\"FairBatch (Sampler in DataLoader).\n",
    "    \n",
    "    This class is for implementing batch selection of FairBatch.\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, train_dataset, lbd, client_idx, batch_size, replacement = False, seed = 0):\n",
    "        \"\"\"Initializes FairBatch.\"\"\"\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.N = train_dataset.y.shape[0]\n",
    "        self.batch_num = int(self.N / self.batch_size)\n",
    "        self.lbd = lbd\n",
    "        \n",
    "        self.yz_index = {}\n",
    "        \n",
    "        for y, z in itertools.product([0,1], [0,1]):\n",
    "                self.yz_index[(y,z)] = np.where((train_dataset.y == y) & (train_dataset.sen == z))[0]\n",
    "\n",
    "    def select_batch_replacement(self, batch_size, full_index, batch_num, replacement = False):\n",
    "        \"\"\"Selects a certain number of batches based on the given batch size.\n",
    "        \n",
    "        Args: \n",
    "            batch_size: An integer for the data size in a batch.\n",
    "            full_index: An array containing the candidate data indices.\n",
    "            batch_num: An integer indicating the number of batches.\n",
    "            replacement: A boolean indicating whether a batch consists of data with or without replacement.\n",
    "        \n",
    "        Returns:\n",
    "            Indices that indicate the data.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        select_index = []\n",
    "        \n",
    "        if replacement == True:\n",
    "            for _ in range(batch_num):\n",
    "                select_index.append(np.random.choice(full_index, batch_size, replace = False))\n",
    "        else:\n",
    "            tmp_index = full_index.copy()\n",
    "            random.shuffle(tmp_index)\n",
    "            \n",
    "            start_idx = 0\n",
    "            for i in range(batch_num):\n",
    "                if start_idx + batch_size > len(full_index):\n",
    "                    select_index.append(np.concatenate((tmp_index[start_idx:], tmp_index[ : batch_size - (len(full_index)-start_idx)])))\n",
    "                    start_idx = len(full_index)-start_idx\n",
    "                else:\n",
    "                    select_index.append(tmp_index[start_idx:start_idx + batch_size])\n",
    "                    start_idx += batch_size\n",
    "        return select_index\n",
    "\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Iters the full process of FairBatch for serving the batches to training.\n",
    "        \n",
    "        Returns:\n",
    "            Indices that indicate the data in each batch.\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        # Get the indices for each class\n",
    "        sort_index_y_1_z_1 = self.select_batch_replacement(int(self.lbd[(1,1)] * self.batch_size), self.yz_index[(1,1)], self.batch_num)\n",
    "        sort_index_y_0_z_1 = self.select_batch_replacement(int(self.lbd[(0,1)] * self.batch_size), self.yz_index[(0,1)], self.batch_num)\n",
    "        sort_index_y_1_z_0 = self.select_batch_replacement(int(self.lbd[(1,0)] * self.batch_size), self.yz_index[(1,0)], self.batch_num)\n",
    "        sort_index_y_0_z_0 = self.select_batch_replacement(int(self.lbd[(0,0)] * self.batch_size), self.yz_index[(0,0)], self.batch_num)\n",
    "\n",
    "\n",
    "        for i in range(self.batch_num):\n",
    "            key_in_fairbatch = sort_index_y_0_z_0[i].copy()\n",
    "            key_in_fairbatch = np.hstack((key_in_fairbatch, sort_index_y_1_z_0[i].copy()))\n",
    "            key_in_fairbatch = np.hstack((key_in_fairbatch, sort_index_y_0_z_1[i].copy()))\n",
    "            key_in_fairbatch = np.hstack((key_in_fairbatch, sort_index_y_1_z_1[i].copy()))\n",
    "\n",
    "            random.shuffle(key_in_fairbatch)\n",
    "            for idx in key_in_fairbatch:\n",
    "                yield idx\n",
    "            # yield key_in_fairbatch\n",
    "                               \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of data.\"\"\"\n",
    "        \n",
    "        return self.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientUpdate(object):\n",
    "    def __init__(self, dataset, idxs, batch_size, option, penalty = 0, lbd = None):\n",
    "        self.trainloader, self.validloader = self.train_val(dataset, list(idxs), batch_size, option, lbd)\n",
    "        self.dataset = dataset\n",
    "        self.option = option\n",
    "        self.penalty = penalty\n",
    "            \n",
    "    def train_val(self, dataset, idxs, batch_size, option, lbd):\n",
    "        \"\"\"\n",
    "        Returns train, validation for a given local training dataset\n",
    "        and user indexes.\n",
    "        \"\"\"\n",
    "        \n",
    "        # split indexes for train, validation (90, 10)\n",
    "        idxs_train = idxs[:int(0.9*len(idxs))]\n",
    "        idxs_val = idxs[int(0.9*len(idxs)):len(idxs)]\n",
    "        \n",
    "        if option == \"FairBatch\": \n",
    "            # FairBatch(self, train_dataset, lbd, client_idx, batch_size, replacement = False, seed = 0)\n",
    "            sampler = FairBatch(DatasetSplit(dataset, idxs_train), lbd, idxs,\n",
    "                                 batch_size = batch_size, replacement = False, seed = 0)\n",
    "            trainloader = DataLoader(DatasetSplit(dataset, idxs_train), sampler = sampler,\n",
    "                                     batch_size=batch_size, num_workers = 0)\n",
    "                        \n",
    "        else:\n",
    "            trainloader = DataLoader(DatasetSplit(dataset, idxs_train),\n",
    "                                     batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        validloader = DataLoader(DatasetSplit(dataset, idxs_val),\n",
    "                                     batch_size=int(len(idxs_val)/10), shuffle=False)\n",
    "        return trainloader, validloader\n",
    "\n",
    "    def update_weights(self, model, global_round, learning_rate, local_epochs, optimizer):\n",
    "        # Set mode to train model\n",
    "        model.train()\n",
    "        epoch_loss = []\n",
    "\n",
    "        # Set optimizer for the local updates\n",
    "        if optimizer == 'sgd':\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                                        ) # momentum=0.5\n",
    "        elif optimizer == 'adam':\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                                         weight_decay=1e-4)\n",
    "\n",
    "        for i in range(local_epochs):\n",
    "            batch_loss = []\n",
    "            for batch_idx, (features, labels, sensitive) in enumerate(self.trainloader):\n",
    "                features, labels = features.to(DEVICE), labels.to(DEVICE).type(torch.LongTensor)\n",
    "                # we need to set the gradients to zero before starting to do backpropragation \n",
    "                # because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "                # This is convenient while training RNNs\n",
    "\n",
    "                log_probs, logits = model(features)\n",
    "                loss, _, _ = loss_func(self.option,\n",
    "                    logits, labels, logits, sensitive, mean_sensitive, self.penalty)\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if batch_idx % 50 == 0:\n",
    "                    print('| Global Round : {} | Local Epoch : {} | [{}/{} ({:.0f}%)]\\tBatch Loss: {:.6f}'.format(\n",
    "                        global_round, i, batch_idx * len(features),\n",
    "                        len(self.trainloader.dataset),\n",
    "                        100. * batch_idx / len(self.trainloader), loss.item()))\n",
    "                batch_loss.append(loss.item())\n",
    "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "\n",
    "        # weight, loss\n",
    "        return model.state_dict(), sum(epoch_loss) / len(epoch_loss)\n",
    "\n",
    "    def inference(self, model, option):\n",
    "        \"\"\" \n",
    "        Returns the inference accuracy, \n",
    "                                loss, \n",
    "                                N(sensitive group, pos), \n",
    "                                N(non-sensitive group, pos), \n",
    "                                N(sensitive group),\n",
    "                                N(non-sensitive group),\n",
    "                                acc_loss,\n",
    "                                fair_loss\n",
    "        \"\"\"\n",
    "\n",
    "        model.eval()\n",
    "        loss, total, correct, fair_loss, acc_loss, num_batch = 0.0, 0.0, 0.0, 0.0, 0.0, 0\n",
    "        n_yz = {(0,0):0, (0,1):0, (1,0):0, (1,1):0}\n",
    "        loss_yz = {(0,0):0, (0,1):0, (1,0):0, (1,1):0}\n",
    "        \n",
    "        dataset = self.validloader if option != \"FairBatch\" else self.dataset\n",
    "        for batch_idx, (features, labels, sensitive) in enumerate(self.validloader):\n",
    "            features, labels = features.to(DEVICE), labels.to(DEVICE).type(torch.LongTensor)\n",
    "            sensitive = sensitive.to(DEVICE)\n",
    "            \n",
    "            # Inference\n",
    "            outputs, logits = model(features)\n",
    "\n",
    "            # Prediction\n",
    "            _, pred_labels = torch.max(outputs, 1)\n",
    "            pred_labels = pred_labels.view(-1)\n",
    "            bool_correct = torch.eq(pred_labels, labels)\n",
    "            correct += torch.sum(bool_correct).item()\n",
    "            total += len(labels)\n",
    "            num_batch += 1\n",
    "            \n",
    "            group_boolean_idx = {}\n",
    "            \n",
    "            \n",
    "            for yz in n_yz:\n",
    "                group_boolean_idx[yz] = (pred_labels == yz[0]) & (sensitive == yz[1])\n",
    "                n_yz[yz] += torch.sum(group_boolean_idx[yz]).item()            \n",
    "                \n",
    "                if self.option == \"FairBatch\":\n",
    "                # the objective function have no lagrangian term\n",
    "                    loss_yz_,_,_ = loss_func(\"unconstrained\", outputs[group_boolean_idx[yz]], \n",
    "                                                    labels[group_boolean_idx[yz]], \n",
    "                                         logits[group_boolean_idx[yz]], sensitive[group_boolean_idx[yz]], \n",
    "                                         mean_sensitive, self.penalty)\n",
    "                    loss_yz[yz] += loss_yz_\n",
    "            \n",
    "            batch_loss, batch_acc_loss, batch_fair_loss = loss_func(self.option, outputs, \n",
    "                                                        labels, logits, sensitive, mean_sensitive, self.penalty)\n",
    "            loss, acc_loss, fair_loss = (loss + batch_loss.item(), \n",
    "                                         acc_loss + batch_acc_loss.item(), \n",
    "                                         fair_loss + batch_fair_loss.item())\n",
    "        accuracy = correct/total\n",
    "        if option == \"FairBatch\":\n",
    "            return accuracy, loss, n_yz, acc_loss / num_batch, fair_loss / num_batch, loss_yz\n",
    "        else:\n",
    "            return accuracy, loss, n_yz, acc_loss / num_batch, fair_loss / num_batch, None\n",
    "\n",
    "# TODO: need to update the criterion to loss_func\n",
    "def test_inference(model, test_dataset, batch_size):\n",
    "    \"\"\" Returns the test accuracy and loss.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "    n_yz = {(0,0):0, (0,1):0, (1,0):0, (1,1):0}\n",
    "    \n",
    "    criterion = nn.NLLLoss().to(DEVICE)\n",
    "    testloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                            shuffle=False)\n",
    "\n",
    "    for batch_idx, (features, labels, sensitive) in enumerate(testloader):\n",
    "        features = features.to(DEVICE)\n",
    "        labels =  labels.to(DEVICE).type(torch.LongTensor)\n",
    "        # Inference\n",
    "        outputs, logits = model(features)\n",
    "        batch_loss = criterion(outputs, labels)\n",
    "        loss += batch_loss.item()\n",
    "\n",
    "        # Prediction\n",
    "        _, pred_labels = torch.max(outputs, 1)\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "        bool_correct = torch.eq(pred_labels, labels)\n",
    "        correct += torch.sum(bool_correct).item()\n",
    "        total += len(labels)\n",
    "        \n",
    "        for yz in n_yz:\n",
    "            n_yz[yz] += torch.sum((pred_labels == yz[0]) & (sensitive == yz[1])).item()  \n",
    "            \n",
    "#         # classified negative, nonsensitive\n",
    "#         n_yz[(0,0)] += torch.sum(torch.logical_and(torch.logical_not(pred_labels), torch.logical_not(sensitive))).item()\n",
    "#         # classified negative, sensitive\n",
    "#         n_yz[(0,1)] += torch.sum(torch.logical_and(torch.logical_not(pred_labels), sensitive)).item()\n",
    "#         # classified positive, nonsensitive\n",
    "#         n_yz[(1,0)] += torch.sum(torch.logical_and(pred_labels, torch.logical_not(sensitive))).item()\n",
    "#         # classified positive, sensitive\n",
    "#         n_yz[(1,1)] += torch.sum(torch.logical_and(pred_labels, sensitive)).item()\n",
    "\n",
    "    accuracy = correct/total\n",
    "    # |P(Group1, pos) - P(Group2, pos)| = |N(Group1, pos)/N(Group1) - N(Group2, pos)/N(Group2)|\n",
    "    return accuracy, loss, RD(n_yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, option = \"unconstrained\", batch_size = 128, num_clients = 2,\n",
    "          num_rounds = 5, learning_rate = 0.01, optimizer = 'adam', local_epochs= 5, \n",
    "          num_workers = 4, print_every = 1,\n",
    "         penalty = 1, alpha = 0.005, seed = 123):\n",
    "    \"\"\"\n",
    "    Server execution.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "        \n",
    "    # Training\n",
    "    train_loss, train_accuracy = [], []\n",
    "    val_acc_list, net_list = [], []\n",
    "    cv_loss, cv_acc = [], []\n",
    "    val_loss_pre, counter = 0, 0\n",
    "    start_time = time.time()\n",
    "    weights = model.state_dict()\n",
    "    \n",
    "    test_loader = DataLoader(dataset = test_dataset,\n",
    "                            batch_size = batch_size,\n",
    "                            num_workers = num_workers)\n",
    "    \n",
    "    train_loader = DataLoader(dataset = train_dataset,\n",
    "                        batch_size = batch_size,\n",
    "                        num_workers = num_workers)\n",
    "\n",
    "    def average_weights(w):\n",
    "        \"\"\"\n",
    "        Returns the average of the weights.\n",
    "        \"\"\"\n",
    "        w_avg = copy.deepcopy(w[0])\n",
    "        for key in w_avg.keys():\n",
    "            for i in range(1, len(w)):\n",
    "                w_avg[key] += w[i][key]\n",
    "            w_avg[key] = torch.div(w_avg[key], len(w))\n",
    "        return w_avg\n",
    "\n",
    "    # the number of samples whose label is y and sensitive attribute is z\n",
    "    m_yz = {(0,0): ((train_dataset.y == 0) & (train_dataset.sen == 0)).sum(),\n",
    "           (1,0): ((train_dataset.y == 1) & (train_dataset.sen == 0)).sum(),\n",
    "           (0,1): ((train_dataset.y == 0) & (train_dataset.sen == 1)).sum(),\n",
    "           (1,1): ((train_dataset.y == 1) & (train_dataset.sen == 1)).sum()}\n",
    "    \n",
    "    lbd = {\n",
    "        (0,0): m_yz[(0,0)]/train_dataset.y.shape[0], \n",
    "        (0,1): m_yz[(0,1)]/train_dataset.y.shape[0],\n",
    "        (1,0): m_yz[(0,1)]/train_dataset.y.shape[0],\n",
    "        (1,1): m_yz[(1,1)]/train_dataset.y.shape[0],\n",
    "          }\n",
    "    \n",
    "    for round_ in tqdm(range(num_rounds)):\n",
    "        local_weights, local_losses = [], []\n",
    "        print(f'\\n | Global Training Round : {round_+1} |\\n')\n",
    "\n",
    "        model.train()\n",
    "        m = 2 # the number of clients to be chosen in each round_\n",
    "        idxs_users = np.random.choice(range(num_clients), m, replace=False)\n",
    "\n",
    "        for idx in idxs_users:\n",
    "            local_model = ClientUpdate(dataset=train_dataset,\n",
    "                                        idxs=clients_idx[idx], batch_size = batch_size, \n",
    "                                       option = option, penalty = penalty, lbd = lbd)\n",
    "            w, loss = local_model.update_weights(\n",
    "                            model=copy.deepcopy(model), global_round=round_, \n",
    "                                learning_rate = learning_rate, local_epochs = local_epochs, \n",
    "                                optimizer = optimizer)\n",
    "            local_weights.append(copy.deepcopy(w))\n",
    "            local_losses.append(copy.deepcopy(loss))\n",
    "\n",
    "        # update global weights\n",
    "        weights = average_weights(local_weights)\n",
    "        model.load_state_dict(weights)\n",
    "\n",
    "        loss_avg = sum(local_losses) / len(local_losses)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        # Calculate avg training accuracy over all clients at every round\n",
    "        list_acc, list_loss = [], []\n",
    "        # the number of samples which are assigned to class y and belong to the sensitive group z\n",
    "        n_yz = {(0,0):0, (0,1):0, (1,0):0, (1,1):0}\n",
    "        loss_yz = {(0,0):0, (0,1):0, (1,0):0, (1,1):0}\n",
    "        model.eval()\n",
    "        for c in range(m):\n",
    "            local_model = ClientUpdate(dataset=train_dataset,\n",
    "                                        idxs=clients_idx[c], batch_size = batch_size, option = option, \n",
    "                                       penalty = penalty, lbd = lbd)\n",
    "            # validation dataset inference\n",
    "            acc, loss, n_yz_c, acc_loss, fair_loss, loss_yz_c = local_model.inference(model = model, \n",
    "                                                                                      option = option) \n",
    "            list_acc.append(acc)\n",
    "            list_loss.append(loss)\n",
    "            \n",
    "            for yz in n_yz:\n",
    "                n_yz[yz] += n_yz_c[yz]\n",
    "                \n",
    "                if option == \"FairBatch\": loss_yz[yz] += loss_yz_c[yz]\n",
    "                \n",
    "            print(\"Client %d: accuracy loss: %.2f | fairness loss %.2f | RD = %.2f = |%d/%d-%d/%d| \" % (\n",
    "                c, acc_loss, fair_loss, RD(n_yz_c), n_yz_c[(1,1)], n_yz_c[(1,1)] + n_yz_c[(0,1)], \n",
    "                n_yz_c[(1,0)], n_yz_c[(1,0)] + n_yz_c[(0,0)]))\n",
    "            \n",
    "        if option == \"FairBatch\": # update the lambda\n",
    "\n",
    "            if abs(loss_yz[(0,0)]/m_yz[(0,0)] - loss_yz[(1,0)]/m_yz[(1,0)]) >= \\\n",
    "                abs(loss_yz[(0,1)]/m_yz[(0,1)] - loss_yz[(1,1)]/m_yz[(1,1)]):\n",
    "                lbd[(0,0)] -= alpha * (2*int((loss_yz[(0,0)]/m_yz[(0,0)] - loss_yz[(1,0)]/m_yz[(1,0)]) > 0)-1)\n",
    "                lbd[(0,1)] = (m_yz[(0,0)] + m_yz[(0,1)])/train_dataset.y.shape[0] - lbd[(0,0)]\n",
    "            else:\n",
    "                lbd[(1,0)] -= alpha * (2*int((loss_yz[(0,1)]/m_yz[(0,1)] - loss_yz[(1,1)]/m_yz[(1,1)]) > 0)-1)\n",
    "                lbd[(1,1)] = (m_yz[(1,0)] + m_yz[(1,1)])/train_dataset.y.shape[0] - lbd[(1,0)]\n",
    "            \n",
    "        train_accuracy.append(sum(list_acc)/len(list_acc))\n",
    "\n",
    "        # print global training loss after every 'i' rounds\n",
    "        if (round_+1) % print_every == 0:\n",
    "            print(f' \\nAvg Training Stats after {round_+1} global rounds:')\n",
    "            if option != \"FairBatch\":\n",
    "                print(\"Training loss: %.2f | Validation accuracy: %.2f%% | Validation RD: %.2f\" % (\n",
    "                     np.mean(np.array(train_loss)), \n",
    "                    100*train_accuracy[-1], RD(n_yz)))\n",
    "            else:\n",
    "                print(\"Training loss: %.2f | Training accuracy: %.2f%% | Training RD: %.2f\" % (\n",
    "                     np.mean(np.array(train_loss)), \n",
    "                    100*train_accuracy[-1], RD(n_yz)))\n",
    "\n",
    "    # Test inference after completion of training\n",
    "    test_acc, test_loss, rd= test_inference(model, test_dataset, batch_size)\n",
    "\n",
    "    print(f' \\n Results after {num_rounds} global rounds of training:')\n",
    "    print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n",
    "    print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))\n",
    "\n",
    "    # Compute RD: risk difference - fairness metric\n",
    "    # |P(Group1, pos) - P(Group2, pos)| = |N(Group1, pos)/N(Group1) - N(Group2, pos)/N(Group2)|\n",
    "    print(\"|---- Test RD: {:.2f}\".format(rd))\n",
    "\n",
    "    print('\\n Total Run Time: {0:0.4f} sec'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 1 |\n",
      "\n",
      "| Global Round : 0 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 90.878746\n",
      "| Global Round : 0 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 53.193573\n",
      "| Global Round : 0 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 40.159161\n",
      "| Global Round : 0 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 45.825268\n",
      "| Global Round : 0 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 49.567120\n",
      "| Global Round : 0 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 47.455147\n",
      "| Global Round : 0 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 50.780552\n",
      "| Global Round : 0 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 40.212395\n",
      "| Global Round : 0 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 51.044689\n",
      "| Global Round : 0 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 36.907444\n",
      "| Global Round : 0 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 93.284721\n",
      "| Global Round : 0 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 49.114399\n",
      "| Global Round : 0 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 50.735851\n",
      "| Global Round : 0 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 35.475594\n",
      "| Global Round : 0 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 50.361511\n",
      "| Global Round : 0 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 38.548080\n",
      "| Global Round : 0 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 47.523823\n",
      "| Global Round : 0 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 37.067646\n",
      "| Global Round : 0 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 41.764339\n",
      "| Global Round : 0 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 37.159367\n",
      "| Global Round : 0 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 35.861256\n",
      "| Global Round : 0 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 44.195385\n",
      "| Global Round : 0 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 37.855591\n",
      "| Global Round : 0 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 38.068295\n",
      "| Global Round : 0 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 50.850426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:03<00:15,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 103.63 | fairness loss 0.43 | RD = 0.30 = |101/592-669/1421| \n",
      "Client 1: accuracy loss: 60.87 | fairness loss 0.61 | RD = 0.25 = |56/421-313/823| \n",
      " \n",
      "Avg Training Stats after 1 global rounds:\n",
      "Training loss: 48.40 | Validation accuracy: 80.87% | Validation RD: 0.28\n",
      "\n",
      " | Global Training Round : 2 |\n",
      "\n",
      "| Global Round : 1 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 30.665058\n",
      "| Global Round : 1 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 41.343723\n",
      "| Global Round : 1 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 36.266209\n",
      "| Global Round : 1 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 34.759308\n",
      "| Global Round : 1 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 40.490913\n",
      "| Global Round : 1 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 44.845722\n",
      "| Global Round : 1 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 31.810749\n",
      "| Global Round : 1 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 47.987617\n",
      "| Global Round : 1 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 46.184536\n",
      "| Global Round : 1 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 27.173178\n",
      "| Global Round : 1 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 48.157879\n",
      "| Global Round : 1 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 65.531662\n",
      "| Global Round : 1 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 50.139790\n",
      "| Global Round : 1 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 43.250366\n",
      "| Global Round : 1 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 39.042507\n",
      "| Global Round : 1 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 61.348389\n",
      "| Global Round : 1 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 64.107971\n",
      "| Global Round : 1 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 43.069481\n",
      "| Global Round : 1 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 65.465172\n",
      "| Global Round : 1 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 39.710533\n",
      "| Global Round : 1 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 48.719547\n",
      "| Global Round : 1 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 46.539944\n",
      "| Global Round : 1 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 49.262772\n",
      "| Global Round : 1 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 41.149403\n",
      "| Global Round : 1 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 64.333092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:07<00:11,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 104.34 | fairness loss 0.46 | RD = 0.38 = |99/592-775/1421| \n",
      "Client 1: accuracy loss: 61.65 | fairness loss 0.57 | RD = 0.33 = |58/421-384/823| \n",
      " \n",
      "Avg Training Stats after 2 global rounds:\n",
      "Training loss: 47.04 | Validation accuracy: 79.31% | Validation RD: 0.36\n",
      "\n",
      " | Global Training Round : 3 |\n",
      "\n",
      "| Global Round : 2 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 57.099686\n",
      "| Global Round : 2 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 44.997437\n",
      "| Global Round : 2 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 43.518169\n",
      "| Global Round : 2 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 46.735432\n",
      "| Global Round : 2 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 44.330078\n",
      "| Global Round : 2 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 28.009600\n",
      "| Global Round : 2 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 56.129921\n",
      "| Global Round : 2 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 49.335629\n",
      "| Global Round : 2 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 53.599342\n",
      "| Global Round : 2 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 50.103081\n",
      "| Global Round : 2 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 41.198532\n",
      "| Global Round : 2 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 43.378315\n",
      "| Global Round : 2 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 40.621273\n",
      "| Global Round : 2 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 55.931156\n",
      "| Global Round : 2 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 43.993477\n",
      "| Global Round : 2 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 51.246510\n",
      "| Global Round : 2 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 36.012676\n",
      "| Global Round : 2 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 45.608047\n",
      "| Global Round : 2 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 30.105772\n",
      "| Global Round : 2 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 32.265293\n",
      "| Global Round : 2 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 32.945843\n",
      "| Global Round : 2 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 40.974998\n",
      "| Global Round : 2 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 42.067276\n",
      "| Global Round : 2 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 41.806087\n",
      "| Global Round : 2 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 47.142696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:11<00:07,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 100.14 | fairness loss 0.59 | RD = 0.27 = |77/592-567/1421| \n",
      "Client 1: accuracy loss: 59.61 | fairness loss 0.72 | RD = 0.26 = |42/421-299/823| \n",
      " \n",
      "Avg Training Stats after 3 global rounds:\n",
      "Training loss: 46.31 | Validation accuracy: 82.83% | Validation RD: 0.27\n",
      "\n",
      " | Global Training Round : 4 |\n",
      "\n",
      "| Global Round : 3 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 46.188766\n",
      "| Global Round : 3 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 36.990242\n",
      "| Global Round : 3 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 40.829140\n",
      "| Global Round : 3 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 46.472935\n",
      "| Global Round : 3 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 39.828655\n",
      "| Global Round : 3 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 51.923923\n",
      "| Global Round : 3 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 37.704254\n",
      "| Global Round : 3 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 72.646362\n",
      "| Global Round : 3 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 56.700706\n",
      "| Global Round : 3 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 51.489876\n",
      "| Global Round : 3 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 32.805012\n",
      "| Global Round : 3 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 31.599339\n",
      "| Global Round : 3 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 33.887817\n",
      "| Global Round : 3 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 35.142529\n",
      "| Global Round : 3 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 38.865314\n",
      "| Global Round : 3 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 33.564587\n",
      "| Global Round : 3 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 43.939434\n",
      "| Global Round : 3 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 38.829517\n",
      "| Global Round : 3 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 34.678101\n",
      "| Global Round : 3 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 28.521687\n",
      "| Global Round : 3 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 46.588299\n",
      "| Global Round : 3 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 40.780743\n",
      "| Global Round : 3 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 41.328667\n",
      "| Global Round : 3 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 31.035509\n",
      "| Global Round : 3 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 47.859634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:15<00:03,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 100.26 | fairness loss 0.59 | RD = 0.28 = |82/592-594/1421| \n",
      "Client 1: accuracy loss: 59.69 | fairness loss 0.70 | RD = 0.27 = |48/421-315/823| \n",
      " \n",
      "Avg Training Stats after 4 global rounds:\n",
      "Training loss: 45.82 | Validation accuracy: 82.61% | Validation RD: 0.28\n",
      "\n",
      " | Global Training Round : 5 |\n",
      "\n",
      "| Global Round : 4 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 49.766724\n",
      "| Global Round : 4 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 47.591393\n",
      "| Global Round : 4 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 47.119442\n",
      "| Global Round : 4 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 41.633862\n",
      "| Global Round : 4 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 58.509113\n",
      "| Global Round : 4 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 34.114101\n",
      "| Global Round : 4 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 53.478104\n",
      "| Global Round : 4 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 51.273594\n",
      "| Global Round : 4 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 54.533440\n",
      "| Global Round : 4 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 44.055660\n",
      "| Global Round : 4 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 36.210026\n",
      "| Global Round : 4 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 41.030670\n",
      "| Global Round : 4 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 38.779732\n",
      "| Global Round : 4 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 32.242607\n",
      "| Global Round : 4 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 44.675419\n",
      "| Global Round : 4 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 36.732689\n",
      "| Global Round : 4 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 36.612244\n",
      "| Global Round : 4 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 32.270290\n",
      "| Global Round : 4 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 42.837357\n",
      "| Global Round : 4 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 31.053272\n",
      "| Global Round : 4 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 46.943359\n",
      "| Global Round : 4 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 40.273167\n",
      "| Global Round : 4 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 40.488514\n",
      "| Global Round : 4 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 34.280888\n",
      "| Global Round : 4 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 38.316738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:18<00:00,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 98.34 | fairness loss 0.65 | RD = 0.19 = |77/592-455/1421| \n",
      "Client 1: accuracy loss: 58.96 | fairness loss 0.76 | RD = 0.19 = |42/421-240/823| \n",
      " \n",
      "Avg Training Stats after 5 global rounds:\n",
      "Training loss: 45.48 | Validation accuracy: 83.66% | Validation RD: 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Results after 5 global rounds of training:\n",
      "|---- Avg Train Accuracy: 83.66%\n",
      "|---- Test Accuracy: 84.58%\n",
      "|---- Test RD: 0.16\n",
      "\n",
      " Total Run Time: 19.2994 sec\n"
     ]
    }
   ],
   "source": [
    "train(logReg(num_features=NUM_FEATURES, num_classes=2), optimizer = 'sgd', learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 1 |\n",
      "\n",
      "| Global Round : 0 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 91.087540\n",
      "| Global Round : 0 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 107.725006\n",
      "| Global Round : 0 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 45.530258\n",
      "| Global Round : 0 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 57.458233\n",
      "| Global Round : 0 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 61.342957\n",
      "| Global Round : 0 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 63.603767\n",
      "| Global Round : 0 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 67.874146\n",
      "| Global Round : 0 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 100.446243\n",
      "| Global Round : 0 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 54.705631\n",
      "| Global Round : 0 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 102.820938\n",
      "| Global Round : 0 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 44.603512\n",
      "| Global Round : 0 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 64.342941\n",
      "| Global Round : 0 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 58.961258\n",
      "| Global Round : 0 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 71.887215\n",
      "| Global Round : 0 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 46.813007\n",
      "| Global Round : 0 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 74.636269\n",
      "| Global Round : 0 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 43.176361\n",
      "| Global Round : 0 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 137.334442\n",
      "| Global Round : 0 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 39.963776\n",
      "| Global Round : 0 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 68.075546\n",
      "| Global Round : 0 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 95.505524\n",
      "| Global Round : 0 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 119.713867\n",
      "| Global Round : 0 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 127.899536\n",
      "| Global Round : 0 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 62.589996\n",
      "| Global Round : 0 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 53.407951\n",
      "| Global Round : 0 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 117.495140\n",
      "| Global Round : 0 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 65.122375\n",
      "| Global Round : 0 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 44.808685\n",
      "| Global Round : 0 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 112.055458\n",
      "| Global Round : 0 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 46.208614\n",
      "| Global Round : 0 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 69.690666\n",
      "| Global Round : 0 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 65.291313\n",
      "| Global Round : 0 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 68.284660\n",
      "| Global Round : 0 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 106.788391\n",
      "| Global Round : 0 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 58.758080\n",
      "| Global Round : 0 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 82.949356\n",
      "| Global Round : 0 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 88.702332\n",
      "| Global Round : 0 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 33.322090\n",
      "| Global Round : 0 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 82.249710\n",
      "| Global Round : 0 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 49.194927\n",
      "| Global Round : 0 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 52.645317\n",
      "| Global Round : 0 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 56.430824\n",
      "| Global Round : 0 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 118.273262\n",
      "| Global Round : 0 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 151.160431\n",
      "| Global Round : 0 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 61.500233\n",
      "| Global Round : 0 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 109.938271\n",
      "| Global Round : 0 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 73.925697\n",
      "| Global Round : 0 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 52.276840\n",
      "| Global Round : 0 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 82.463638\n",
      "| Global Round : 0 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 91.272232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:07<00:30,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 107.03 | fairness loss 0.60 | RD = 0.30 = |98/592-661/1421| \n",
      "Client 1: accuracy loss: 63.55 | fairness loss 0.87 | RD = 0.24 = |57/421-308/823| \n",
      " \n",
      "Avg Training Stats after 1 global rounds:\n",
      "Training loss: 81.47 | Validation accuracy: 81.13% | Validation RD: 0.28\n",
      "\n",
      " | Global Training Round : 2 |\n",
      "\n",
      "| Global Round : 1 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 47.653412\n",
      "| Global Round : 1 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 33.277695\n",
      "| Global Round : 1 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 43.634350\n",
      "| Global Round : 1 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 46.054932\n",
      "| Global Round : 1 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 179.703430\n",
      "| Global Round : 1 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 60.887173\n",
      "| Global Round : 1 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 61.975349\n",
      "| Global Round : 1 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 87.575302\n",
      "| Global Round : 1 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 117.529877\n",
      "| Global Round : 1 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 51.106541\n",
      "| Global Round : 1 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 72.205032\n",
      "| Global Round : 1 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 43.173359\n",
      "| Global Round : 1 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 63.741997\n",
      "| Global Round : 1 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 60.411461\n",
      "| Global Round : 1 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 72.845894\n",
      "| Global Round : 1 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 46.532936\n",
      "| Global Round : 1 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 38.135559\n",
      "| Global Round : 1 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 124.875290\n",
      "| Global Round : 1 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 43.327435\n",
      "| Global Round : 1 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 74.552895\n",
      "| Global Round : 1 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 65.127510\n",
      "| Global Round : 1 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 63.939259\n",
      "| Global Round : 1 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 71.918587\n",
      "| Global Round : 1 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 62.725349\n",
      "| Global Round : 1 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 50.600964\n",
      "| Global Round : 1 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 41.542675\n",
      "| Global Round : 1 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 113.265068\n",
      "| Global Round : 1 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 53.790798\n",
      "| Global Round : 1 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 84.424316\n",
      "| Global Round : 1 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 72.113297\n",
      "| Global Round : 1 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 53.006104\n",
      "| Global Round : 1 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 55.275936\n",
      "| Global Round : 1 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 37.769440\n",
      "| Global Round : 1 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 44.854935\n",
      "| Global Round : 1 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 65.752556\n",
      "| Global Round : 1 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 60.063210\n",
      "| Global Round : 1 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 53.365784\n",
      "| Global Round : 1 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 80.540932\n",
      "| Global Round : 1 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 44.119347\n",
      "| Global Round : 1 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 82.608696\n",
      "| Global Round : 1 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 48.993046\n",
      "| Global Round : 1 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 80.419815\n",
      "| Global Round : 1 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 50.508991\n",
      "| Global Round : 1 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 52.323242\n",
      "| Global Round : 1 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 45.973942\n",
      "| Global Round : 1 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 95.191513\n",
      "| Global Round : 1 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 44.145992\n",
      "| Global Round : 1 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 84.648781\n",
      "| Global Round : 1 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 55.698204\n",
      "| Global Round : 1 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 48.679493\n",
      "Client 0: accuracy loss: 109.83 | fairness loss 1.08 | RD = 0.33 = |110/592-729/1421| \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:15<00:22,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1: accuracy loss: 66.02 | fairness loss 1.24 | RD = 0.27 = |67/421-357/823| \n",
      " \n",
      "Avg Training Stats after 2 global rounds:\n",
      "Training loss: 76.24 | Validation accuracy: 79.64% | Validation RD: 0.31\n",
      "\n",
      " | Global Training Round : 3 |\n",
      "\n",
      "| Global Round : 2 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 43.293701\n",
      "| Global Round : 2 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 80.951660\n",
      "| Global Round : 2 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 56.765831\n",
      "| Global Round : 2 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 69.372635\n",
      "| Global Round : 2 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 57.854992\n",
      "| Global Round : 2 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 151.669785\n",
      "| Global Round : 2 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 43.432163\n",
      "| Global Round : 2 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 63.521297\n",
      "| Global Round : 2 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 46.914642\n",
      "| Global Round : 2 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 101.448303\n",
      "| Global Round : 2 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 51.969929\n",
      "| Global Round : 2 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 54.175617\n",
      "| Global Round : 2 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 39.992676\n",
      "| Global Round : 2 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 107.631317\n",
      "| Global Round : 2 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 56.180489\n",
      "| Global Round : 2 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 59.441246\n",
      "| Global Round : 2 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 47.631905\n",
      "| Global Round : 2 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 36.127441\n",
      "| Global Round : 2 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 44.293495\n",
      "| Global Round : 2 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 47.297497\n",
      "| Global Round : 2 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 55.206741\n",
      "| Global Round : 2 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 74.634956\n",
      "| Global Round : 2 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 67.179466\n",
      "| Global Round : 2 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 42.737885\n",
      "| Global Round : 2 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 84.382629\n",
      "| Global Round : 2 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 60.119385\n",
      "| Global Round : 2 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 57.156548\n",
      "| Global Round : 2 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 51.173374\n",
      "| Global Round : 2 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 60.312557\n",
      "| Global Round : 2 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 59.823997\n",
      "| Global Round : 2 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 86.965210\n",
      "| Global Round : 2 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 48.437920\n",
      "| Global Round : 2 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 43.053684\n",
      "| Global Round : 2 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 50.961231\n",
      "| Global Round : 2 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 31.397602\n",
      "| Global Round : 2 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 48.655148\n",
      "| Global Round : 2 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 96.662239\n",
      "| Global Round : 2 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 65.882965\n",
      "| Global Round : 2 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 65.010597\n",
      "| Global Round : 2 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 107.481873\n",
      "| Global Round : 2 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 73.561478\n",
      "| Global Round : 2 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 44.069359\n",
      "| Global Round : 2 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 82.149384\n",
      "| Global Round : 2 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 140.633759\n",
      "| Global Round : 2 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 38.818668\n",
      "| Global Round : 2 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 49.314991\n",
      "| Global Round : 2 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 39.803669\n",
      "| Global Round : 2 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 55.656723\n",
      "| Global Round : 2 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 53.330921\n",
      "| Global Round : 2 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 94.508682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:23<00:15,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 102.26 | fairness loss 1.53 | RD = 0.23 = |67/592-492/1421| \n",
      "Client 1: accuracy loss: 61.50 | fairness loss 2.16 | RD = 0.19 = |40/421-238/823| \n",
      " \n",
      "Avg Training Stats after 3 global rounds:\n",
      "Training loss: 74.28 | Validation accuracy: 83.55% | Validation RD: 0.22\n",
      "\n",
      " | Global Training Round : 4 |\n",
      "\n",
      "| Global Round : 3 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 45.724056\n",
      "| Global Round : 3 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 113.324051\n",
      "| Global Round : 3 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 71.110764\n",
      "| Global Round : 3 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 94.089920\n",
      "| Global Round : 3 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 42.827278\n",
      "| Global Round : 3 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 51.726265\n",
      "| Global Round : 3 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 40.988510\n",
      "| Global Round : 3 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 119.347359\n",
      "| Global Round : 3 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 61.465599\n",
      "| Global Round : 3 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 55.999222\n",
      "| Global Round : 3 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 53.731461\n",
      "| Global Round : 3 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 48.767643\n",
      "| Global Round : 3 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 48.366386\n",
      "| Global Round : 3 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 57.668877\n",
      "| Global Round : 3 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 46.985203\n",
      "| Global Round : 3 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 63.969669\n",
      "| Global Round : 3 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 40.616405\n",
      "| Global Round : 3 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 42.895660\n",
      "| Global Round : 3 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 46.481388\n",
      "| Global Round : 3 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 124.538918\n",
      "| Global Round : 3 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 52.360222\n",
      "| Global Round : 3 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 60.814064\n",
      "| Global Round : 3 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 63.613186\n",
      "| Global Round : 3 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 28.151545\n",
      "| Global Round : 3 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 146.864471\n",
      "| Global Round : 3 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 68.584160\n",
      "| Global Round : 3 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 45.123539\n",
      "| Global Round : 3 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 33.991997\n",
      "| Global Round : 3 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 44.110813\n",
      "| Global Round : 3 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 43.113140\n",
      "| Global Round : 3 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 70.014206\n",
      "| Global Round : 3 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 47.297245\n",
      "| Global Round : 3 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 56.952122\n",
      "| Global Round : 3 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 84.752045\n",
      "| Global Round : 3 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 49.526527\n",
      "| Global Round : 3 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 34.559750\n",
      "| Global Round : 3 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 45.847332\n",
      "| Global Round : 3 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 90.162643\n",
      "| Global Round : 3 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 55.801910\n",
      "| Global Round : 3 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 45.050537\n",
      "| Global Round : 3 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 115.811661\n",
      "| Global Round : 3 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 38.657913\n",
      "| Global Round : 3 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 38.755280\n",
      "| Global Round : 3 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 53.589314\n",
      "| Global Round : 3 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 57.051445\n",
      "| Global Round : 3 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 46.140366\n",
      "| Global Round : 3 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 40.689518\n",
      "| Global Round : 3 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 58.980713\n",
      "| Global Round : 3 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 43.930458\n",
      "| Global Round : 3 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 43.112236\n",
      "Client 0: accuracy loss: 105.36 | fairness loss 0.26 | RD = 0.22 = |86/592-513/1421| \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:30<00:07,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1: accuracy loss: 63.73 | fairness loss 0.26 | RD = 0.21 = |46/421-265/823| \n",
      " \n",
      "Avg Training Stats after 4 global rounds:\n",
      "Training loss: 72.68 | Validation accuracy: 83.84% | Validation RD: 0.22\n",
      "\n",
      " | Global Training Round : 5 |\n",
      "\n",
      "| Global Round : 4 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 56.079002\n",
      "| Global Round : 4 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 32.749493\n",
      "| Global Round : 4 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 44.470371\n",
      "| Global Round : 4 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 57.926239\n",
      "| Global Round : 4 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 35.525433\n",
      "| Global Round : 4 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 108.887573\n",
      "| Global Round : 4 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 47.313347\n",
      "| Global Round : 4 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 67.285103\n",
      "| Global Round : 4 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 49.684402\n",
      "| Global Round : 4 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 38.070808\n",
      "| Global Round : 4 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 49.330463\n",
      "| Global Round : 4 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 45.879807\n",
      "| Global Round : 4 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 49.198532\n",
      "| Global Round : 4 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 54.141518\n",
      "| Global Round : 4 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 45.737083\n",
      "| Global Round : 4 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 129.995544\n",
      "| Global Round : 4 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 38.089905\n",
      "| Global Round : 4 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 59.923000\n",
      "| Global Round : 4 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 53.559784\n",
      "| Global Round : 4 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 51.134480\n",
      "| Global Round : 4 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 32.532158\n",
      "| Global Round : 4 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 76.040230\n",
      "| Global Round : 4 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 47.083668\n",
      "| Global Round : 4 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 75.133987\n",
      "| Global Round : 4 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 87.486130\n",
      "| Global Round : 4 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 51.985466\n",
      "| Global Round : 4 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 37.300091\n",
      "| Global Round : 4 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 81.000221\n",
      "| Global Round : 4 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 77.592445\n",
      "| Global Round : 4 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 67.411865\n",
      "| Global Round : 4 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 45.443630\n",
      "| Global Round : 4 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 93.417038\n",
      "| Global Round : 4 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 77.522003\n",
      "| Global Round : 4 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 78.831184\n",
      "| Global Round : 4 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 119.513908\n",
      "| Global Round : 4 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 38.357414\n",
      "| Global Round : 4 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 50.333694\n",
      "| Global Round : 4 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 100.193604\n",
      "| Global Round : 4 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 48.607674\n",
      "| Global Round : 4 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 65.521057\n",
      "| Global Round : 4 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 44.032330\n",
      "| Global Round : 4 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 37.939789\n",
      "| Global Round : 4 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 57.228386\n",
      "| Global Round : 4 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 92.542542\n",
      "| Global Round : 4 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 30.050692\n",
      "| Global Round : 4 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 101.064072\n",
      "| Global Round : 4 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 49.552750\n",
      "| Global Round : 4 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 45.212612\n",
      "| Global Round : 4 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 40.699596\n",
      "| Global Round : 4 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 74.876549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:37<00:00,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 103.54 | fairness loss 0.87 | RD = 0.26 = |66/592-528/1421| \n",
      "Client 1: accuracy loss: 62.40 | fairness loss 1.02 | RD = 0.25 = |40/421-280/823| \n",
      " \n",
      "Avg Training Stats after 5 global rounds:\n",
      "Training loss: 71.61 | Validation accuracy: 83.51% | Validation RD: 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Results after 5 global rounds of training:\n",
      "|---- Avg Train Accuracy: 83.51%\n",
      "|---- Test Accuracy: 84.46%\n",
      "|---- Test RD: 0.20\n",
      "\n",
      " Total Run Time: 38.2369 sec\n"
     ]
    }
   ],
   "source": [
    "train(logReg(num_features=NUM_FEATURES, num_classes=2), \n",
    "      \"Zafar\", penalty = 50, optimizer = 'sgd', learning_rate = 0.01,\n",
    "     num_rounds = 5, local_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 1 |\n",
      "\n",
      "| Global Round : 0 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 88.324371\n",
      "| Global Round : 0 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 76.816750\n",
      "| Global Round : 0 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 54.973553\n",
      "| Global Round : 0 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 53.144211\n",
      "| Global Round : 0 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 45.883881\n",
      "| Global Round : 0 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 57.148705\n",
      "| Global Round : 0 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 45.879372\n",
      "| Global Round : 0 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 50.717587\n",
      "| Global Round : 0 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 51.708126\n",
      "| Global Round : 0 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 43.595169\n",
      "| Global Round : 0 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 42.206825\n",
      "| Global Round : 0 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 62.472843\n",
      "| Global Round : 0 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 52.337975\n",
      "| Global Round : 0 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 55.844582\n",
      "| Global Round : 0 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 46.129211\n",
      "| Global Round : 0 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 50.251434\n",
      "| Global Round : 0 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 46.365250\n",
      "| Global Round : 0 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 45.947186\n",
      "| Global Round : 0 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 60.189468\n",
      "| Global Round : 0 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 51.578880\n",
      "| Global Round : 0 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 88.045830\n",
      "| Global Round : 0 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 60.032482\n",
      "| Global Round : 0 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 47.651802\n",
      "| Global Round : 0 | Local Epoch : 0 | [17550/18116 (106%)]\tBatch Loss: 54.814991\n",
      "| Global Round : 0 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 44.098351\n",
      "| Global Round : 0 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 46.631737\n",
      "| Global Round : 0 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 45.018539\n",
      "| Global Round : 0 | Local Epoch : 1 | [17550/18116 (106%)]\tBatch Loss: 47.638222\n",
      "| Global Round : 0 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 46.377094\n",
      "| Global Round : 0 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 48.062714\n",
      "| Global Round : 0 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 46.028484\n",
      "| Global Round : 0 | Local Epoch : 2 | [17550/18116 (106%)]\tBatch Loss: 36.566956\n",
      "| Global Round : 0 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 47.838116\n",
      "| Global Round : 0 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 50.588894\n",
      "| Global Round : 0 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 61.149960\n",
      "| Global Round : 0 | Local Epoch : 3 | [17550/18116 (106%)]\tBatch Loss: 39.270550\n",
      "| Global Round : 0 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 41.648224\n",
      "| Global Round : 0 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 53.757290\n",
      "| Global Round : 0 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 48.921768\n",
      "| Global Round : 0 | Local Epoch : 4 | [17550/18116 (106%)]\tBatch Loss: 45.549316\n",
      "| Global Round : 0 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 46.378178\n",
      "| Global Round : 0 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 42.106667\n",
      "| Global Round : 0 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 49.117775\n",
      "| Global Round : 0 | Local Epoch : 5 | [17550/18116 (106%)]\tBatch Loss: 35.187614\n",
      "| Global Round : 0 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 43.784382\n",
      "| Global Round : 0 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 52.865810\n",
      "| Global Round : 0 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 54.065964\n",
      "| Global Round : 0 | Local Epoch : 6 | [17550/18116 (106%)]\tBatch Loss: 34.596409\n",
      "| Global Round : 0 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 46.289360\n",
      "| Global Round : 0 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 41.606182\n",
      "| Global Round : 0 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 45.123158\n",
      "| Global Round : 0 | Local Epoch : 7 | [17550/18116 (106%)]\tBatch Loss: 46.990898\n",
      "| Global Round : 0 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 45.518929\n",
      "| Global Round : 0 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 43.791626\n",
      "| Global Round : 0 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 41.706665\n",
      "| Global Round : 0 | Local Epoch : 8 | [17550/18116 (106%)]\tBatch Loss: 47.588615\n",
      "| Global Round : 0 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 33.150063\n",
      "| Global Round : 0 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 49.597324\n",
      "| Global Round : 0 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 36.332218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [00:08<02:44,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 0 | Local Epoch : 9 | [17550/18116 (106%)]\tBatch Loss: 44.065224\n",
      "Client 0: accuracy loss: 104.66 | fairness loss 0.42 | RD = 0.40 = |91/592-780/1421| \n",
      "Client 1: accuracy loss: 61.11 | fairness loss 0.59 | RD = 0.32 = |52/421-362/823| \n",
      " \n",
      "Avg Training Stats after 1 global rounds:\n",
      "Training loss: 50.86 | Training accuracy: 79.28% | Training RD: 0.37\n",
      "\n",
      " | Global Training Round : 2 |\n",
      "\n",
      "| Global Round : 1 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 48.539951\n",
      "| Global Round : 1 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 51.615456\n",
      "| Global Round : 1 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 44.478088\n",
      "| Global Round : 1 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 53.917126\n",
      "| Global Round : 1 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 43.242596\n",
      "| Global Round : 1 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 41.952991\n",
      "| Global Round : 1 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 45.442455\n",
      "| Global Round : 1 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 49.981922\n",
      "| Global Round : 1 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 52.505573\n",
      "| Global Round : 1 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 44.165825\n",
      "| Global Round : 1 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 45.322323\n",
      "| Global Round : 1 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 50.926041\n",
      "| Global Round : 1 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 36.263332\n",
      "| Global Round : 1 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 48.099941\n",
      "| Global Round : 1 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 46.536423\n",
      "| Global Round : 1 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 45.205822\n",
      "| Global Round : 1 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 48.353775\n",
      "| Global Round : 1 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 45.267876\n",
      "| Global Round : 1 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 41.883579\n",
      "| Global Round : 1 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 51.727898\n",
      "| Global Round : 1 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 46.635136\n",
      "| Global Round : 1 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 47.250919\n",
      "| Global Round : 1 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 61.624187\n",
      "| Global Round : 1 | Local Epoch : 0 | [19200/18116 (106%)]\tBatch Loss: 45.383762\n",
      "| Global Round : 1 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 49.683037\n",
      "| Global Round : 1 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 49.389858\n",
      "| Global Round : 1 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 62.140617\n",
      "| Global Round : 1 | Local Epoch : 1 | [19200/18116 (106%)]\tBatch Loss: 50.500168\n",
      "| Global Round : 1 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 43.448868\n",
      "| Global Round : 1 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 53.886230\n",
      "| Global Round : 1 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 42.518963\n",
      "| Global Round : 1 | Local Epoch : 2 | [19200/18116 (106%)]\tBatch Loss: 66.132698\n",
      "| Global Round : 1 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 41.156170\n",
      "| Global Round : 1 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 30.358065\n",
      "| Global Round : 1 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 45.576569\n",
      "| Global Round : 1 | Local Epoch : 3 | [19200/18116 (106%)]\tBatch Loss: 37.182800\n",
      "| Global Round : 1 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 36.279865\n",
      "| Global Round : 1 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 38.396568\n",
      "| Global Round : 1 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 40.088654\n",
      "| Global Round : 1 | Local Epoch : 4 | [19200/18116 (106%)]\tBatch Loss: 45.517929\n",
      "| Global Round : 1 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 50.021969\n",
      "| Global Round : 1 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 43.709049\n",
      "| Global Round : 1 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 31.397509\n",
      "| Global Round : 1 | Local Epoch : 5 | [19200/18116 (106%)]\tBatch Loss: 55.822948\n",
      "| Global Round : 1 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 38.512367\n",
      "| Global Round : 1 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 40.767433\n",
      "| Global Round : 1 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 56.622280\n",
      "| Global Round : 1 | Local Epoch : 6 | [19200/18116 (106%)]\tBatch Loss: 40.975121\n",
      "| Global Round : 1 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 52.877659\n",
      "| Global Round : 1 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 46.837830\n",
      "| Global Round : 1 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 37.789921\n",
      "| Global Round : 1 | Local Epoch : 7 | [19200/18116 (106%)]\tBatch Loss: 52.451794\n",
      "| Global Round : 1 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 50.972832\n",
      "| Global Round : 1 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 59.547600\n",
      "| Global Round : 1 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 46.304253\n",
      "| Global Round : 1 | Local Epoch : 8 | [19200/18116 (106%)]\tBatch Loss: 47.186695\n",
      "| Global Round : 1 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 40.789242\n",
      "| Global Round : 1 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 40.452068\n",
      "| Global Round : 1 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 36.330704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:17<02:36,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 1 | Local Epoch : 9 | [19200/18116 (106%)]\tBatch Loss: 38.556561\n",
      "Client 0: accuracy loss: 102.55 | fairness loss 0.51 | RD = 0.38 = |92/592-755/1421| \n",
      "Client 1: accuracy loss: 60.34 | fairness loss 0.64 | RD = 0.32 = |53/421-368/823| \n",
      " \n",
      "Avg Training Stats after 2 global rounds:\n",
      "Training loss: 49.71 | Training accuracy: 79.97% | Training RD: 0.36\n",
      "\n",
      " | Global Training Round : 3 |\n",
      "\n",
      "| Global Round : 2 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 46.863960\n",
      "| Global Round : 2 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 47.532959\n",
      "| Global Round : 2 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 54.720505\n",
      "| Global Round : 2 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 50.675308\n",
      "| Global Round : 2 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 45.078712\n",
      "| Global Round : 2 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 51.701900\n",
      "| Global Round : 2 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 41.491261\n",
      "| Global Round : 2 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 59.807751\n",
      "| Global Round : 2 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 47.533485\n",
      "| Global Round : 2 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 37.128204\n",
      "| Global Round : 2 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 41.649620\n",
      "| Global Round : 2 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 54.853371\n",
      "| Global Round : 2 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 55.993187\n",
      "| Global Round : 2 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 37.689159\n",
      "| Global Round : 2 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 47.088081\n",
      "| Global Round : 2 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 52.540199\n",
      "| Global Round : 2 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 41.211788\n",
      "| Global Round : 2 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 40.932858\n",
      "| Global Round : 2 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 59.389492\n",
      "| Global Round : 2 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 50.204105\n",
      "| Global Round : 2 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 46.017487\n",
      "| Global Round : 2 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 40.240768\n",
      "| Global Round : 2 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 34.860413\n",
      "| Global Round : 2 | Local Epoch : 0 | [17550/18116 (106%)]\tBatch Loss: 48.630890\n",
      "| Global Round : 2 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 40.707035\n",
      "| Global Round : 2 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 60.571804\n",
      "| Global Round : 2 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 40.427994\n",
      "| Global Round : 2 | Local Epoch : 1 | [17550/18116 (106%)]\tBatch Loss: 46.316738\n",
      "| Global Round : 2 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 44.640114\n",
      "| Global Round : 2 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 49.494164\n",
      "| Global Round : 2 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 76.555321\n",
      "| Global Round : 2 | Local Epoch : 2 | [17550/18116 (106%)]\tBatch Loss: 33.344700\n",
      "| Global Round : 2 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 54.668457\n",
      "| Global Round : 2 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 44.125988\n",
      "| Global Round : 2 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 52.017681\n",
      "| Global Round : 2 | Local Epoch : 3 | [17550/18116 (106%)]\tBatch Loss: 40.858253\n",
      "| Global Round : 2 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 42.856033\n",
      "| Global Round : 2 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 35.907238\n",
      "| Global Round : 2 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 39.177078\n",
      "| Global Round : 2 | Local Epoch : 4 | [17550/18116 (106%)]\tBatch Loss: 46.457016\n",
      "| Global Round : 2 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 44.300900\n",
      "| Global Round : 2 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 52.470699\n",
      "| Global Round : 2 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 45.419357\n",
      "| Global Round : 2 | Local Epoch : 5 | [17550/18116 (106%)]\tBatch Loss: 37.678581\n",
      "| Global Round : 2 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 42.642311\n",
      "| Global Round : 2 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 36.637875\n",
      "| Global Round : 2 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 46.083820\n",
      "| Global Round : 2 | Local Epoch : 6 | [17550/18116 (106%)]\tBatch Loss: 39.419487\n",
      "| Global Round : 2 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 44.753830\n",
      "| Global Round : 2 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 40.035313\n",
      "| Global Round : 2 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 39.924755\n",
      "| Global Round : 2 | Local Epoch : 7 | [17550/18116 (106%)]\tBatch Loss: 42.529327\n",
      "| Global Round : 2 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 44.787338\n",
      "| Global Round : 2 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 39.663311\n",
      "| Global Round : 2 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 34.535458\n",
      "| Global Round : 2 | Local Epoch : 8 | [17550/18116 (106%)]\tBatch Loss: 44.756310\n",
      "| Global Round : 2 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 33.372124\n",
      "| Global Round : 2 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 41.966640\n",
      "| Global Round : 2 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 33.228317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:25<02:26,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 2 | Local Epoch : 9 | [17550/18116 (106%)]\tBatch Loss: 43.274254\n",
      "Client 0: accuracy loss: 100.44 | fairness loss 0.57 | RD = 0.33 = |72/592-637/1421| \n",
      "Client 1: accuracy loss: 59.65 | fairness loss 0.68 | RD = 0.30 = |42/421-333/823| \n",
      " \n",
      "Avg Training Stats after 3 global rounds:\n",
      "Training loss: 49.04 | Training accuracy: 81.94% | Training RD: 0.32\n",
      "\n",
      " | Global Training Round : 4 |\n",
      "\n",
      "| Global Round : 3 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 42.299759\n",
      "| Global Round : 3 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 40.997105\n",
      "| Global Round : 3 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 53.854061\n",
      "| Global Round : 3 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 53.061558\n",
      "| Global Round : 3 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 43.980556\n",
      "| Global Round : 3 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 55.148830\n",
      "| Global Round : 3 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 45.127010\n",
      "| Global Round : 3 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 61.331268\n",
      "| Global Round : 3 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 52.440250\n",
      "| Global Round : 3 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 42.010269\n",
      "| Global Round : 3 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 44.856392\n",
      "| Global Round : 3 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 57.255009\n",
      "| Global Round : 3 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 50.207863\n",
      "| Global Round : 3 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 50.264633\n",
      "| Global Round : 3 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 44.078136\n",
      "| Global Round : 3 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 57.750919\n",
      "| Global Round : 3 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 45.719505\n",
      "| Global Round : 3 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 48.756420\n",
      "| Global Round : 3 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 57.498833\n",
      "| Global Round : 3 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 43.267887\n",
      "| Global Round : 3 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 45.879723\n",
      "| Global Round : 3 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 49.138676\n",
      "| Global Round : 3 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 37.823303\n",
      "| Global Round : 3 | Local Epoch : 0 | [17550/18116 (106%)]\tBatch Loss: 49.296558\n",
      "| Global Round : 3 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 43.141197\n",
      "| Global Round : 3 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 48.220955\n",
      "| Global Round : 3 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 44.021740\n",
      "| Global Round : 3 | Local Epoch : 1 | [17550/18116 (106%)]\tBatch Loss: 49.160580\n",
      "| Global Round : 3 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 43.707424\n",
      "| Global Round : 3 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 42.432903\n",
      "| Global Round : 3 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 48.808430\n",
      "| Global Round : 3 | Local Epoch : 2 | [17550/18116 (106%)]\tBatch Loss: 36.659851\n",
      "| Global Round : 3 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 49.889370\n",
      "| Global Round : 3 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 45.267574\n",
      "| Global Round : 3 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 60.787106\n",
      "| Global Round : 3 | Local Epoch : 3 | [17550/18116 (106%)]\tBatch Loss: 41.878181\n",
      "| Global Round : 3 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 43.572262\n",
      "| Global Round : 3 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 41.119526\n",
      "| Global Round : 3 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 47.269054\n",
      "| Global Round : 3 | Local Epoch : 4 | [17550/18116 (106%)]\tBatch Loss: 47.798344\n",
      "| Global Round : 3 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 42.695618\n",
      "| Global Round : 3 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 61.116810\n",
      "| Global Round : 3 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 47.488789\n",
      "| Global Round : 3 | Local Epoch : 5 | [17550/18116 (106%)]\tBatch Loss: 37.077457\n",
      "| Global Round : 3 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 43.082176\n",
      "| Global Round : 3 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 39.108788\n",
      "| Global Round : 3 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 50.738838\n",
      "| Global Round : 3 | Local Epoch : 6 | [17550/18116 (106%)]\tBatch Loss: 33.172802\n",
      "| Global Round : 3 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 43.664413\n",
      "| Global Round : 3 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 43.471237\n",
      "| Global Round : 3 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 47.627758\n",
      "| Global Round : 3 | Local Epoch : 7 | [17550/18116 (106%)]\tBatch Loss: 49.047668\n",
      "| Global Round : 3 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 44.658474\n",
      "| Global Round : 3 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 58.315338\n",
      "| Global Round : 3 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 32.285748\n",
      "| Global Round : 3 | Local Epoch : 8 | [17550/18116 (106%)]\tBatch Loss: 40.771057\n",
      "| Global Round : 3 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 37.904938\n",
      "| Global Round : 3 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 56.048656\n",
      "| Global Round : 3 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 33.319401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:34<02:17,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 3 | Local Epoch : 9 | [17550/18116 (106%)]\tBatch Loss: 55.233047\n",
      "Client 0: accuracy loss: 100.08 | fairness loss 0.59 | RD = 0.33 = |71/592-636/1421| \n",
      "Client 1: accuracy loss: 59.60 | fairness loss 0.69 | RD = 0.31 = |42/421-334/823| \n",
      " \n",
      "Avg Training Stats after 4 global rounds:\n",
      "Training loss: 48.67 | Training accuracy: 82.31% | Training RD: 0.32\n",
      "\n",
      " | Global Training Round : 5 |\n",
      "\n",
      "| Global Round : 4 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 42.056763\n",
      "| Global Round : 4 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 59.483006\n",
      "| Global Round : 4 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 38.501385\n",
      "| Global Round : 4 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 43.125313\n",
      "| Global Round : 4 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 42.480927\n",
      "| Global Round : 4 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 41.383617\n",
      "| Global Round : 4 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 45.817764\n",
      "| Global Round : 4 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 50.098148\n",
      "| Global Round : 4 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 59.597836\n",
      "| Global Round : 4 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 39.049061\n",
      "| Global Round : 4 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 43.057968\n",
      "| Global Round : 4 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 50.584721\n",
      "| Global Round : 4 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 40.194145\n",
      "| Global Round : 4 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 50.491528\n",
      "| Global Round : 4 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 48.473183\n",
      "| Global Round : 4 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 47.675053\n",
      "| Global Round : 4 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 46.254097\n",
      "| Global Round : 4 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 52.268761\n",
      "| Global Round : 4 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 44.882145\n",
      "| Global Round : 4 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 43.895992\n",
      "| Global Round : 4 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 41.898521\n",
      "| Global Round : 4 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 49.489094\n",
      "| Global Round : 4 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 52.647266\n",
      "| Global Round : 4 | Local Epoch : 0 | [19200/18116 (106%)]\tBatch Loss: 41.330215\n",
      "| Global Round : 4 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 42.715500\n",
      "| Global Round : 4 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 45.590714\n",
      "| Global Round : 4 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 41.361252\n",
      "| Global Round : 4 | Local Epoch : 1 | [19200/18116 (106%)]\tBatch Loss: 50.838249\n",
      "| Global Round : 4 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 50.223087\n",
      "| Global Round : 4 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 40.457096\n",
      "| Global Round : 4 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 38.236328\n",
      "| Global Round : 4 | Local Epoch : 2 | [19200/18116 (106%)]\tBatch Loss: 49.721497\n",
      "| Global Round : 4 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 43.893936\n",
      "| Global Round : 4 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 41.245445\n",
      "| Global Round : 4 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 63.831638\n",
      "| Global Round : 4 | Local Epoch : 3 | [19200/18116 (106%)]\tBatch Loss: 33.547913\n",
      "| Global Round : 4 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 36.245670\n",
      "| Global Round : 4 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 37.585178\n",
      "| Global Round : 4 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 53.361443\n",
      "| Global Round : 4 | Local Epoch : 4 | [19200/18116 (106%)]\tBatch Loss: 35.487762\n",
      "| Global Round : 4 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 52.176083\n",
      "| Global Round : 4 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 35.061237\n",
      "| Global Round : 4 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 41.701180\n",
      "| Global Round : 4 | Local Epoch : 5 | [19200/18116 (106%)]\tBatch Loss: 53.949730\n",
      "| Global Round : 4 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 37.618088\n",
      "| Global Round : 4 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 51.869503\n",
      "| Global Round : 4 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 44.948116\n",
      "| Global Round : 4 | Local Epoch : 6 | [19200/18116 (106%)]\tBatch Loss: 43.364880\n",
      "| Global Round : 4 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 45.564529\n",
      "| Global Round : 4 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 46.888596\n",
      "| Global Round : 4 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 43.981098\n",
      "| Global Round : 4 | Local Epoch : 7 | [19200/18116 (106%)]\tBatch Loss: 44.563858\n",
      "| Global Round : 4 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 50.290794\n",
      "| Global Round : 4 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 46.498581\n",
      "| Global Round : 4 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 38.122353\n",
      "| Global Round : 4 | Local Epoch : 8 | [19200/18116 (106%)]\tBatch Loss: 61.107738\n",
      "| Global Round : 4 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 45.270935\n",
      "| Global Round : 4 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 45.526917\n",
      "| Global Round : 4 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 43.286621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [00:42<02:08,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 4 | Local Epoch : 9 | [19200/18116 (106%)]\tBatch Loss: 46.332958\n",
      "Client 0: accuracy loss: 98.81 | fairness loss 0.66 | RD = 0.30 = |74/592-602/1421| \n",
      "Client 1: accuracy loss: 58.96 | fairness loss 0.75 | RD = 0.29 = |42/421-317/823| \n",
      " \n",
      "Avg Training Stats after 5 global rounds:\n",
      "Training loss: 48.44 | Training accuracy: 83.17% | Training RD: 0.30\n",
      "\n",
      " | Global Training Round : 6 |\n",
      "\n",
      "| Global Round : 5 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 41.900215\n",
      "| Global Round : 5 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 54.513451\n",
      "| Global Round : 5 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 56.575787\n",
      "| Global Round : 5 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 47.079613\n",
      "| Global Round : 5 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 45.539238\n",
      "| Global Round : 5 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 56.111713\n",
      "| Global Round : 5 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 42.089661\n",
      "| Global Round : 5 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 59.166157\n",
      "| Global Round : 5 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 47.534981\n",
      "| Global Round : 5 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 40.613388\n",
      "| Global Round : 5 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 44.204418\n",
      "| Global Round : 5 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 57.446922\n",
      "| Global Round : 5 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 49.441437\n",
      "| Global Round : 5 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 52.428097\n",
      "| Global Round : 5 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 41.844189\n",
      "| Global Round : 5 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 54.070354\n",
      "| Global Round : 5 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 45.152851\n",
      "| Global Round : 5 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 45.916218\n",
      "| Global Round : 5 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 57.776840\n",
      "| Global Round : 5 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 49.123188\n",
      "| Global Round : 5 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 42.695011\n",
      "| Global Round : 5 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 55.824341\n",
      "| Global Round : 5 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 33.638252\n",
      "| Global Round : 5 | Local Epoch : 0 | [17550/18116 (106%)]\tBatch Loss: 45.500687\n",
      "| Global Round : 5 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 39.527805\n",
      "| Global Round : 5 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 45.312500\n",
      "| Global Round : 5 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 40.024025\n",
      "| Global Round : 5 | Local Epoch : 1 | [17550/18116 (106%)]\tBatch Loss: 40.409454\n",
      "| Global Round : 5 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 42.739845\n",
      "| Global Round : 5 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 47.508850\n",
      "| Global Round : 5 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 55.942554\n",
      "| Global Round : 5 | Local Epoch : 2 | [17550/18116 (106%)]\tBatch Loss: 45.243603\n",
      "| Global Round : 5 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 46.720383\n",
      "| Global Round : 5 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 55.636608\n",
      "| Global Round : 5 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 52.982536\n",
      "| Global Round : 5 | Local Epoch : 3 | [17550/18116 (106%)]\tBatch Loss: 37.618572\n",
      "| Global Round : 5 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 43.718006\n",
      "| Global Round : 5 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 39.392445\n",
      "| Global Round : 5 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 47.010841\n",
      "| Global Round : 5 | Local Epoch : 4 | [17550/18116 (106%)]\tBatch Loss: 43.252735\n",
      "| Global Round : 5 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 39.437538\n",
      "| Global Round : 5 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 52.725441\n",
      "| Global Round : 5 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 44.396301\n",
      "| Global Round : 5 | Local Epoch : 5 | [17550/18116 (106%)]\tBatch Loss: 44.780495\n",
      "| Global Round : 5 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 43.402462\n",
      "| Global Round : 5 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 35.547852\n",
      "| Global Round : 5 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 45.998222\n",
      "| Global Round : 5 | Local Epoch : 6 | [17550/18116 (106%)]\tBatch Loss: 35.531872\n",
      "| Global Round : 5 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 46.204609\n",
      "| Global Round : 5 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 50.903732\n",
      "| Global Round : 5 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 52.079887\n",
      "| Global Round : 5 | Local Epoch : 7 | [17550/18116 (106%)]\tBatch Loss: 43.230080\n",
      "| Global Round : 5 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 45.918777\n",
      "| Global Round : 5 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 58.232407\n",
      "| Global Round : 5 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 36.222412\n",
      "| Global Round : 5 | Local Epoch : 8 | [17550/18116 (106%)]\tBatch Loss: 36.984741\n",
      "| Global Round : 5 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 36.357464\n",
      "| Global Round : 5 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 64.425316\n",
      "| Global Round : 5 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 35.312557\n",
      "| Global Round : 5 | Local Epoch : 9 | [17550/18116 (106%)]\tBatch Loss: 44.550808\n",
      "Client 0: accuracy loss: 98.47 | fairness loss 0.67 | RD = 0.27 = |73/592-553/1421| \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [00:51<02:00,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1: accuracy loss: 58.90 | fairness loss 0.75 | RD = 0.27 = |41/421-299/823| \n",
      " \n",
      "Avg Training Stats after 6 global rounds:\n",
      "Training loss: 48.30 | Training accuracy: 83.60% | Training RD: 0.27\n",
      "\n",
      " | Global Training Round : 7 |\n",
      "\n",
      "| Global Round : 6 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 41.006344\n",
      "| Global Round : 6 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 41.024071\n",
      "| Global Round : 6 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 54.302162\n",
      "| Global Round : 6 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 51.789150\n",
      "| Global Round : 6 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 44.179321\n",
      "| Global Round : 6 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 55.006115\n",
      "| Global Round : 6 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 44.820705\n",
      "| Global Round : 6 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 53.301350\n",
      "| Global Round : 6 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 48.314060\n",
      "| Global Round : 6 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 39.935078\n",
      "| Global Round : 6 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 43.221680\n",
      "| Global Round : 6 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 58.734249\n",
      "| Global Round : 6 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 51.891167\n",
      "| Global Round : 6 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 52.825268\n",
      "| Global Round : 6 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 48.815029\n",
      "| Global Round : 6 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 52.130630\n",
      "| Global Round : 6 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 44.488022\n",
      "| Global Round : 6 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 38.234352\n",
      "| Global Round : 6 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 60.665478\n",
      "| Global Round : 6 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 54.597549\n",
      "| Global Round : 6 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 44.663807\n",
      "| Global Round : 6 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 49.373131\n",
      "| Global Round : 6 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 37.625854\n",
      "| Global Round : 6 | Local Epoch : 0 | [17550/18116 (106%)]\tBatch Loss: 46.456718\n",
      "| Global Round : 6 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 38.959969\n",
      "| Global Round : 6 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 48.736156\n",
      "| Global Round : 6 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 43.496635\n",
      "| Global Round : 6 | Local Epoch : 1 | [17550/18116 (106%)]\tBatch Loss: 51.684643\n",
      "| Global Round : 6 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 45.128269\n",
      "| Global Round : 6 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 50.797031\n",
      "| Global Round : 6 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 55.148277\n",
      "| Global Round : 6 | Local Epoch : 2 | [17550/18116 (106%)]\tBatch Loss: 53.448021\n",
      "| Global Round : 6 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 61.298512\n",
      "| Global Round : 6 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 54.550560\n",
      "| Global Round : 6 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 70.450035\n",
      "| Global Round : 6 | Local Epoch : 3 | [17550/18116 (106%)]\tBatch Loss: 38.056904\n",
      "| Global Round : 6 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 42.568722\n",
      "| Global Round : 6 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 62.141479\n",
      "| Global Round : 6 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 47.498535\n",
      "| Global Round : 6 | Local Epoch : 4 | [17550/18116 (106%)]\tBatch Loss: 47.431149\n",
      "| Global Round : 6 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 40.095409\n",
      "| Global Round : 6 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 39.807728\n",
      "| Global Round : 6 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 76.601067\n",
      "| Global Round : 6 | Local Epoch : 5 | [17550/18116 (106%)]\tBatch Loss: 35.464439\n",
      "| Global Round : 6 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 47.528927\n",
      "| Global Round : 6 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 38.413925\n",
      "| Global Round : 6 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 51.357643\n",
      "| Global Round : 6 | Local Epoch : 6 | [17550/18116 (106%)]\tBatch Loss: 44.932083\n",
      "| Global Round : 6 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 48.493156\n",
      "| Global Round : 6 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 43.281818\n",
      "| Global Round : 6 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 48.379147\n",
      "| Global Round : 6 | Local Epoch : 7 | [17550/18116 (106%)]\tBatch Loss: 40.244747\n",
      "| Global Round : 6 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 45.290955\n",
      "| Global Round : 6 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 48.913456\n",
      "| Global Round : 6 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 37.585979\n",
      "| Global Round : 6 | Local Epoch : 8 | [17550/18116 (106%)]\tBatch Loss: 38.656666\n",
      "| Global Round : 6 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 36.539402\n",
      "| Global Round : 6 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 42.358898\n",
      "| Global Round : 6 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 33.264755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [00:59<01:51,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 6 | Local Epoch : 9 | [17550/18116 (106%)]\tBatch Loss: 44.179142\n",
      "Client 0: accuracy loss: 100.27 | fairness loss 0.63 | RD = 0.34 = |86/592-693/1421| \n",
      "Client 1: accuracy loss: 59.95 | fairness loss 0.70 | RD = 0.34 = |50/421-381/823| \n",
      " \n",
      "Avg Training Stats after 7 global rounds:\n",
      "Training loss: 48.23 | Training accuracy: 81.13% | Training RD: 0.34\n",
      "\n",
      " | Global Training Round : 8 |\n",
      "\n",
      "| Global Round : 7 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 44.523037\n",
      "| Global Round : 7 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 40.920952\n",
      "| Global Round : 7 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 54.534813\n",
      "| Global Round : 7 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 51.587971\n",
      "| Global Round : 7 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 44.109406\n",
      "| Global Round : 7 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 54.854519\n",
      "| Global Round : 7 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 44.893154\n",
      "| Global Round : 7 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 53.216843\n",
      "| Global Round : 7 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 48.195538\n",
      "| Global Round : 7 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 40.033192\n",
      "| Global Round : 7 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 43.303730\n",
      "| Global Round : 7 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 58.406628\n",
      "| Global Round : 7 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 51.644333\n",
      "| Global Round : 7 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 52.780163\n",
      "| Global Round : 7 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 48.578876\n",
      "| Global Round : 7 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 52.046577\n",
      "| Global Round : 7 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 44.500774\n",
      "| Global Round : 7 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 38.228806\n",
      "| Global Round : 7 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 60.828392\n",
      "| Global Round : 7 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 54.406498\n",
      "| Global Round : 7 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 46.970448\n",
      "| Global Round : 7 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 49.195377\n",
      "| Global Round : 7 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 37.576603\n",
      "| Global Round : 7 | Local Epoch : 0 | [17550/18116 (106%)]\tBatch Loss: 46.426571\n",
      "| Global Round : 7 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 38.791191\n",
      "| Global Round : 7 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 48.669323\n",
      "| Global Round : 7 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 43.526749\n",
      "| Global Round : 7 | Local Epoch : 1 | [17550/18116 (106%)]\tBatch Loss: 51.498383\n",
      "| Global Round : 7 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 44.904655\n",
      "| Global Round : 7 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 50.567944\n",
      "| Global Round : 7 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 55.089211\n",
      "| Global Round : 7 | Local Epoch : 2 | [17550/18116 (106%)]\tBatch Loss: 53.056255\n",
      "| Global Round : 7 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 61.123703\n",
      "| Global Round : 7 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 54.422878\n",
      "| Global Round : 7 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 69.989723\n",
      "| Global Round : 7 | Local Epoch : 3 | [17550/18116 (106%)]\tBatch Loss: 37.801704\n",
      "| Global Round : 7 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 42.552765\n",
      "| Global Round : 7 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 61.709904\n",
      "| Global Round : 7 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 47.334873\n",
      "| Global Round : 7 | Local Epoch : 4 | [17550/18116 (106%)]\tBatch Loss: 47.474567\n",
      "| Global Round : 7 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 40.096886\n",
      "| Global Round : 7 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 39.867805\n",
      "| Global Round : 7 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 76.275459\n",
      "| Global Round : 7 | Local Epoch : 5 | [17550/18116 (106%)]\tBatch Loss: 35.507267\n",
      "| Global Round : 7 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 47.514057\n",
      "| Global Round : 7 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 38.453564\n",
      "| Global Round : 7 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 51.496174\n",
      "| Global Round : 7 | Local Epoch : 6 | [17550/18116 (106%)]\tBatch Loss: 44.402512\n",
      "| Global Round : 7 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 48.205280\n",
      "| Global Round : 7 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 43.112675\n",
      "| Global Round : 7 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 48.186607\n",
      "| Global Round : 7 | Local Epoch : 7 | [17550/18116 (106%)]\tBatch Loss: 40.031765\n",
      "| Global Round : 7 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 45.121407\n",
      "| Global Round : 7 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 48.461197\n",
      "| Global Round : 7 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 37.599773\n",
      "| Global Round : 7 | Local Epoch : 8 | [17550/18116 (106%)]\tBatch Loss: 38.600624\n",
      "| Global Round : 7 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 36.500893\n",
      "| Global Round : 7 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 42.331120\n",
      "| Global Round : 7 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 33.118755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [01:08<01:42,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 7 | Local Epoch : 9 | [17550/18116 (106%)]\tBatch Loss: 44.160206\n",
      "Client 0: accuracy loss: 100.10 | fairness loss 0.65 | RD = 0.34 = |84/592-688/1421| \n",
      "Client 1: accuracy loss: 59.85 | fairness loss 0.72 | RD = 0.34 = |50/421-381/823| \n",
      " \n",
      "Avg Training Stats after 8 global rounds:\n",
      "Training loss: 48.16 | Training accuracy: 81.10% | Training RD: 0.34\n",
      "\n",
      " | Global Training Round : 9 |\n",
      "\n",
      "| Global Round : 8 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 43.887062\n",
      "| Global Round : 8 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 46.030048\n",
      "| Global Round : 8 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 57.417145\n",
      "| Global Round : 8 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 65.053894\n",
      "| Global Round : 8 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 44.453377\n",
      "| Global Round : 8 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 45.491451\n",
      "| Global Round : 8 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 44.991302\n",
      "| Global Round : 8 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 61.197964\n",
      "| Global Round : 8 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 47.879860\n",
      "| Global Round : 8 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 35.161339\n",
      "| Global Round : 8 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 45.167042\n",
      "| Global Round : 8 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 49.724072\n",
      "| Global Round : 8 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 49.070396\n",
      "| Global Round : 8 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 53.980846\n",
      "| Global Round : 8 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 41.763901\n",
      "| Global Round : 8 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 52.638165\n",
      "| Global Round : 8 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 43.403164\n",
      "| Global Round : 8 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 45.957069\n",
      "| Global Round : 8 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 59.116325\n",
      "| Global Round : 8 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 49.313271\n",
      "| Global Round : 8 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 47.666176\n",
      "| Global Round : 8 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 59.191986\n",
      "| Global Round : 8 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 48.208572\n",
      "| Global Round : 8 | Local Epoch : 0 | [17550/18116 (106%)]\tBatch Loss: 48.849030\n",
      "| Global Round : 8 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 39.752205\n",
      "| Global Round : 8 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 52.618744\n",
      "| Global Round : 8 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 43.744766\n",
      "| Global Round : 8 | Local Epoch : 1 | [17550/18116 (106%)]\tBatch Loss: 56.841648\n",
      "| Global Round : 8 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 47.868732\n",
      "| Global Round : 8 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 45.880714\n",
      "| Global Round : 8 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 59.759968\n",
      "| Global Round : 8 | Local Epoch : 2 | [17550/18116 (106%)]\tBatch Loss: 42.174263\n",
      "| Global Round : 8 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 48.321869\n",
      "| Global Round : 8 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 50.449154\n",
      "| Global Round : 8 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 56.310173\n",
      "| Global Round : 8 | Local Epoch : 3 | [17550/18116 (106%)]\tBatch Loss: 40.460621\n",
      "| Global Round : 8 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 43.855106\n",
      "| Global Round : 8 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 47.848564\n",
      "| Global Round : 8 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 51.057926\n",
      "| Global Round : 8 | Local Epoch : 4 | [17550/18116 (106%)]\tBatch Loss: 40.564747\n",
      "| Global Round : 8 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 39.570152\n",
      "| Global Round : 8 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 42.921978\n",
      "| Global Round : 8 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 73.547554\n",
      "| Global Round : 8 | Local Epoch : 5 | [17550/18116 (106%)]\tBatch Loss: 40.563370\n",
      "| Global Round : 8 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 42.299816\n",
      "| Global Round : 8 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 37.849258\n",
      "| Global Round : 8 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 44.160980\n",
      "| Global Round : 8 | Local Epoch : 6 | [17550/18116 (106%)]\tBatch Loss: 30.065178\n",
      "| Global Round : 8 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 44.330498\n",
      "| Global Round : 8 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 60.265572\n",
      "| Global Round : 8 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 49.654846\n",
      "| Global Round : 8 | Local Epoch : 7 | [17550/18116 (106%)]\tBatch Loss: 43.256893\n",
      "| Global Round : 8 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 44.330757\n",
      "| Global Round : 8 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 35.975349\n",
      "| Global Round : 8 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 37.844730\n",
      "| Global Round : 8 | Local Epoch : 8 | [17550/18116 (106%)]\tBatch Loss: 37.902355\n",
      "| Global Round : 8 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 35.083012\n",
      "| Global Round : 8 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 49.249641\n",
      "| Global Round : 8 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 38.340767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [01:16<01:33,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 8 | Local Epoch : 9 | [17550/18116 (106%)]\tBatch Loss: 40.617142\n",
      "Client 0: accuracy loss: 96.46 | fairness loss 0.78 | RD = 0.19 = |65/592-425/1421| \n",
      "Client 1: accuracy loss: 57.90 | fairness loss 0.88 | RD = 0.19 = |38/421-230/823| \n",
      " \n",
      "Avg Training Stats after 9 global rounds:\n",
      "Training loss: 48.14 | Training accuracy: 84.13% | Training RD: 0.19\n",
      "\n",
      " | Global Training Round : 10 |\n",
      "\n",
      "| Global Round : 9 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 126.744629\n",
      "| Global Round : 9 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 39.134445\n",
      "| Global Round : 9 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 256.060333\n",
      "| Global Round : 9 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 36.412502\n",
      "| Global Round : 9 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 297.528534\n",
      "| Global Round : 9 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 45.067127\n",
      "| Global Round : 9 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 251.549622\n",
      "| Global Round : 9 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 41.559296\n",
      "| Global Round : 9 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 299.664001\n",
      "| Global Round : 9 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 46.686104\n",
      "| Global Round : 9 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 254.158554\n",
      "| Global Round : 9 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 68.707146\n",
      "| Global Round : 9 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 311.508240\n",
      "| Global Round : 9 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 53.347641\n",
      "| Global Round : 9 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 250.550568\n",
      "| Global Round : 9 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 51.754032\n",
      "| Global Round : 9 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 322.911163\n",
      "| Global Round : 9 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 53.923523\n",
      "| Global Round : 9 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 250.486252\n",
      "| Global Round : 9 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 39.251930\n",
      "| Global Round : 9 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 138.353119\n",
      "| Global Round : 9 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 38.348072\n",
      "| Global Round : 9 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 44.920090\n",
      "| Global Round : 9 | Local Epoch : 0 | [19200/18116 (106%)]\tBatch Loss: 31.821585\n",
      "| Global Round : 9 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 371.973663\n",
      "| Global Round : 9 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 42.917652\n",
      "| Global Round : 9 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 26.341290\n",
      "| Global Round : 9 | Local Epoch : 1 | [19200/18116 (106%)]\tBatch Loss: 38.194756\n",
      "| Global Round : 9 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 353.384521\n",
      "| Global Round : 9 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 51.190781\n",
      "| Global Round : 9 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 28.174797\n",
      "| Global Round : 9 | Local Epoch : 2 | [19200/18116 (106%)]\tBatch Loss: 35.549450\n",
      "| Global Round : 9 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 357.467407\n",
      "| Global Round : 9 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 59.266014\n",
      "| Global Round : 9 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 42.537170\n",
      "| Global Round : 9 | Local Epoch : 3 | [19200/18116 (106%)]\tBatch Loss: 45.241039\n",
      "| Global Round : 9 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 282.067169\n",
      "| Global Round : 9 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 31.387579\n",
      "| Global Round : 9 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 33.185684\n",
      "| Global Round : 9 | Local Epoch : 4 | [19200/18116 (106%)]\tBatch Loss: 47.537899\n",
      "| Global Round : 9 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 298.745087\n",
      "| Global Round : 9 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 32.990406\n",
      "| Global Round : 9 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 43.416260\n",
      "| Global Round : 9 | Local Epoch : 5 | [19200/18116 (106%)]\tBatch Loss: 45.728222\n",
      "| Global Round : 9 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 271.487640\n",
      "| Global Round : 9 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 44.236576\n",
      "| Global Round : 9 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 42.764465\n",
      "| Global Round : 9 | Local Epoch : 6 | [19200/18116 (106%)]\tBatch Loss: 35.272335\n",
      "| Global Round : 9 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 330.939850\n",
      "| Global Round : 9 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 36.317097\n",
      "| Global Round : 9 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 47.954678\n",
      "| Global Round : 9 | Local Epoch : 7 | [19200/18116 (106%)]\tBatch Loss: 53.796577\n",
      "| Global Round : 9 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 245.951889\n",
      "| Global Round : 9 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 41.160908\n",
      "| Global Round : 9 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 33.346584\n",
      "| Global Round : 9 | Local Epoch : 8 | [19200/18116 (106%)]\tBatch Loss: 36.809895\n",
      "| Global Round : 9 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 344.690277\n",
      "| Global Round : 9 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 42.928970\n",
      "| Global Round : 9 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 38.840862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [01:26<01:26,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 9 | Local Epoch : 9 | [19200/18116 (106%)]\tBatch Loss: 44.298523\n",
      "Client 0: accuracy loss: 96.94 | fairness loss 1.48 | RD = 0.39 = |7/592-573/1421| \n",
      "Client 1: accuracy loss: 57.51 | fairness loss 1.66 | RD = 0.36 = |7/421-313/823| \n",
      " \n",
      "Avg Training Stats after 10 global rounds:\n",
      "Training loss: 47.97 | Training accuracy: 81.90% | Training RD: 0.38\n",
      "\n",
      " | Global Training Round : 11 |\n",
      "\n",
      "| Global Round : 10 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 274.726593\n",
      "| Global Round : 10 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 38.904049\n",
      "| Global Round : 10 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 242.929489\n",
      "| Global Round : 10 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 42.885586\n",
      "| Global Round : 10 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 300.894989\n",
      "| Global Round : 10 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 44.516716\n",
      "| Global Round : 10 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 274.648254\n",
      "| Global Round : 10 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 44.654236\n",
      "| Global Round : 10 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 304.108856\n",
      "| Global Round : 10 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 38.585007\n",
      "| Global Round : 10 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 233.192734\n",
      "| Global Round : 10 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 45.902458\n",
      "| Global Round : 10 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 237.513260\n",
      "| Global Round : 10 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 48.009083\n",
      "| Global Round : 10 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 304.079590\n",
      "| Global Round : 10 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 36.462711\n",
      "| Global Round : 10 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 254.205917\n",
      "| Global Round : 10 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 59.600155\n",
      "| Global Round : 10 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 321.820984\n",
      "| Global Round : 10 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 36.874916\n",
      "| Global Round : 10 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 327.888123\n",
      "| Global Round : 10 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 34.765018\n",
      "| Global Round : 10 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 36.945343\n",
      "| Global Round : 10 | Local Epoch : 0 | [17250/18116 (106%)]\tBatch Loss: 44.145699\n",
      "| Global Round : 10 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 371.496399\n",
      "| Global Round : 10 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 35.855461\n",
      "| Global Round : 10 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 31.033590\n",
      "| Global Round : 10 | Local Epoch : 1 | [17250/18116 (106%)]\tBatch Loss: 38.418774\n",
      "| Global Round : 10 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 425.628510\n",
      "| Global Round : 10 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 34.186733\n",
      "| Global Round : 10 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 39.787407\n",
      "| Global Round : 10 | Local Epoch : 2 | [17250/18116 (106%)]\tBatch Loss: 41.409645\n",
      "| Global Round : 10 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 280.703278\n",
      "| Global Round : 10 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 37.699390\n",
      "| Global Round : 10 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 32.897655\n",
      "| Global Round : 10 | Local Epoch : 3 | [17250/18116 (106%)]\tBatch Loss: 33.326771\n",
      "| Global Round : 10 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 369.387238\n",
      "| Global Round : 10 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 53.589352\n",
      "| Global Round : 10 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 40.497181\n",
      "| Global Round : 10 | Local Epoch : 4 | [17250/18116 (106%)]\tBatch Loss: 45.335567\n",
      "| Global Round : 10 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 272.311890\n",
      "| Global Round : 10 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 43.028687\n",
      "| Global Round : 10 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 32.558891\n",
      "| Global Round : 10 | Local Epoch : 5 | [17250/18116 (106%)]\tBatch Loss: 38.188366\n",
      "| Global Round : 10 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 357.289154\n",
      "| Global Round : 10 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 41.946346\n",
      "| Global Round : 10 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 42.856522\n",
      "| Global Round : 10 | Local Epoch : 6 | [17250/18116 (106%)]\tBatch Loss: 29.876066\n",
      "| Global Round : 10 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 292.658173\n",
      "| Global Round : 10 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 46.144020\n",
      "| Global Round : 10 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 43.834286\n",
      "| Global Round : 10 | Local Epoch : 7 | [17250/18116 (106%)]\tBatch Loss: 42.502060\n",
      "| Global Round : 10 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 366.940918\n",
      "| Global Round : 10 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 39.771362\n",
      "| Global Round : 10 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 44.286163\n",
      "| Global Round : 10 | Local Epoch : 8 | [17250/18116 (106%)]\tBatch Loss: 31.272766\n",
      "| Global Round : 10 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 328.079712\n",
      "| Global Round : 10 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 42.902020\n",
      "| Global Round : 10 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 37.475349\n",
      "| Global Round : 10 | Local Epoch : 9 | [17250/18116 (106%)]\tBatch Loss: 34.086250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [01:34<01:18,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 97.54 | fairness loss 1.48 | RD = 0.43 = |7/592-633/1421| \n",
      "Client 1: accuracy loss: 57.79 | fairness loss 1.64 | RD = 0.39 = |8/421-339/823| \n",
      " \n",
      "Avg Training Stats after 11 global rounds:\n",
      "Training loss: 47.79 | Training accuracy: 81.02% | Training RD: 0.42\n",
      "\n",
      " | Global Training Round : 12 |\n",
      "\n",
      "| Global Round : 11 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 272.759186\n",
      "| Global Round : 11 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 42.423996\n",
      "| Global Round : 11 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 223.816299\n",
      "| Global Round : 11 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 49.026535\n",
      "| Global Round : 11 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 229.451675\n",
      "| Global Round : 11 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 51.440506\n",
      "| Global Round : 11 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 265.431641\n",
      "| Global Round : 11 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 37.840919\n",
      "| Global Round : 11 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 292.215118\n",
      "| Global Round : 11 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 48.294323\n",
      "| Global Round : 11 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 224.933792\n",
      "| Global Round : 11 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 55.995403\n",
      "| Global Round : 11 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 295.157745\n",
      "| Global Round : 11 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 43.220997\n",
      "| Global Round : 11 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 276.980103\n",
      "| Global Round : 11 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 56.696590\n",
      "| Global Round : 11 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 296.664825\n",
      "| Global Round : 11 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 53.211597\n",
      "| Global Round : 11 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 298.745605\n",
      "| Global Round : 11 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 34.815891\n",
      "| Global Round : 11 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 316.012451\n",
      "| Global Round : 11 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 38.614807\n",
      "| Global Round : 11 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 43.560665\n",
      "| Global Round : 11 | Local Epoch : 0 | [17250/18116 (106%)]\tBatch Loss: 44.671070\n",
      "| Global Round : 11 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 321.134216\n",
      "| Global Round : 11 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 40.167858\n",
      "| Global Round : 11 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 44.203621\n",
      "| Global Round : 11 | Local Epoch : 1 | [17250/18116 (106%)]\tBatch Loss: 41.381390\n",
      "| Global Round : 11 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 388.858734\n",
      "| Global Round : 11 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 33.889923\n",
      "| Global Round : 11 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 37.187679\n",
      "| Global Round : 11 | Local Epoch : 2 | [17250/18116 (106%)]\tBatch Loss: 43.790146\n",
      "| Global Round : 11 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 274.677094\n",
      "| Global Round : 11 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 38.691422\n",
      "| Global Round : 11 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 28.457890\n",
      "| Global Round : 11 | Local Epoch : 3 | [17250/18116 (106%)]\tBatch Loss: 29.374189\n",
      "| Global Round : 11 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 297.042633\n",
      "| Global Round : 11 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 36.654995\n",
      "| Global Round : 11 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 48.444302\n",
      "| Global Round : 11 | Local Epoch : 4 | [17250/18116 (106%)]\tBatch Loss: 40.513298\n",
      "| Global Round : 11 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 301.361023\n",
      "| Global Round : 11 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 35.553535\n",
      "| Global Round : 11 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 31.930700\n",
      "| Global Round : 11 | Local Epoch : 5 | [17250/18116 (106%)]\tBatch Loss: 37.818512\n",
      "| Global Round : 11 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 335.859833\n",
      "| Global Round : 11 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 39.492920\n",
      "| Global Round : 11 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 35.145012\n",
      "| Global Round : 11 | Local Epoch : 6 | [17250/18116 (106%)]\tBatch Loss: 33.195652\n",
      "| Global Round : 11 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 280.911682\n",
      "| Global Round : 11 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 45.923065\n",
      "| Global Round : 11 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 40.313026\n",
      "| Global Round : 11 | Local Epoch : 7 | [17250/18116 (106%)]\tBatch Loss: 38.780781\n",
      "| Global Round : 11 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 354.892700\n",
      "| Global Round : 11 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 52.484646\n",
      "| Global Round : 11 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 52.896805\n",
      "| Global Round : 11 | Local Epoch : 8 | [17250/18116 (106%)]\tBatch Loss: 37.355694\n",
      "| Global Round : 11 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 358.032349\n",
      "| Global Round : 11 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 39.302338\n",
      "| Global Round : 11 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 43.500538\n",
      "| Global Round : 11 | Local Epoch : 9 | [17250/18116 (106%)]\tBatch Loss: 42.868443\n",
      "Client 0: accuracy loss: 97.34 | fairness loss 1.47 | RD = 0.42 = |9/592-624/1421| \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [01:45<01:14,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1: accuracy loss: 57.70 | fairness loss 1.64 | RD = 0.38 = |9/421-333/823| \n",
      " \n",
      "Avg Training Stats after 12 global rounds:\n",
      "Training loss: 47.68 | Training accuracy: 81.30% | Training RD: 0.41\n",
      "\n",
      " | Global Training Round : 13 |\n",
      "\n",
      "| Global Round : 12 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 266.936035\n",
      "| Global Round : 12 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 42.458565\n",
      "| Global Round : 12 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 221.957977\n",
      "| Global Round : 12 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 48.959896\n",
      "| Global Round : 12 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 229.723145\n",
      "| Global Round : 12 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 51.356449\n",
      "| Global Round : 12 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 264.730988\n",
      "| Global Round : 12 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 37.836006\n",
      "| Global Round : 12 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 291.694763\n",
      "| Global Round : 12 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 48.312325\n",
      "| Global Round : 12 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 224.622772\n",
      "| Global Round : 12 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 55.885677\n",
      "| Global Round : 12 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 294.638916\n",
      "| Global Round : 12 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 43.211143\n",
      "| Global Round : 12 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 276.452301\n",
      "| Global Round : 12 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 56.477367\n",
      "| Global Round : 12 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 296.007385\n",
      "| Global Round : 12 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 53.088036\n",
      "| Global Round : 12 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 297.904236\n",
      "| Global Round : 12 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 34.715511\n",
      "| Global Round : 12 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 311.954346\n",
      "| Global Round : 12 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 38.658108\n",
      "| Global Round : 12 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 43.579311\n",
      "| Global Round : 12 | Local Epoch : 0 | [17250/18116 (106%)]\tBatch Loss: 44.611526\n",
      "| Global Round : 12 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 319.804810\n",
      "| Global Round : 12 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 40.217972\n",
      "| Global Round : 12 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 44.197014\n",
      "| Global Round : 12 | Local Epoch : 1 | [17250/18116 (106%)]\tBatch Loss: 41.283245\n",
      "| Global Round : 12 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 387.315186\n",
      "| Global Round : 12 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 33.804634\n",
      "| Global Round : 12 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 37.122002\n",
      "| Global Round : 12 | Local Epoch : 2 | [17250/18116 (106%)]\tBatch Loss: 43.747746\n",
      "| Global Round : 12 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 274.056335\n",
      "| Global Round : 12 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 38.676968\n",
      "| Global Round : 12 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 28.452513\n",
      "| Global Round : 12 | Local Epoch : 3 | [17250/18116 (106%)]\tBatch Loss: 29.356424\n",
      "| Global Round : 12 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 296.531555\n",
      "| Global Round : 12 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 36.607288\n",
      "| Global Round : 12 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 48.459091\n",
      "| Global Round : 12 | Local Epoch : 4 | [17250/18116 (106%)]\tBatch Loss: 40.549786\n",
      "| Global Round : 12 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 300.997223\n",
      "| Global Round : 12 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 35.665314\n",
      "| Global Round : 12 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 31.930622\n",
      "| Global Round : 12 | Local Epoch : 5 | [17250/18116 (106%)]\tBatch Loss: 37.801910\n",
      "| Global Round : 12 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 335.535583\n",
      "| Global Round : 12 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 39.397896\n",
      "| Global Round : 12 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 35.143452\n",
      "| Global Round : 12 | Local Epoch : 6 | [17250/18116 (106%)]\tBatch Loss: 33.169712\n",
      "| Global Round : 12 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 280.653625\n",
      "| Global Round : 12 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 45.964737\n",
      "| Global Round : 12 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 40.223576\n",
      "| Global Round : 12 | Local Epoch : 7 | [17250/18116 (106%)]\tBatch Loss: 38.650764\n",
      "| Global Round : 12 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 353.961823\n",
      "| Global Round : 12 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 52.444054\n",
      "| Global Round : 12 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 52.907825\n",
      "| Global Round : 12 | Local Epoch : 8 | [17250/18116 (106%)]\tBatch Loss: 37.215378\n",
      "| Global Round : 12 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 357.007111\n",
      "| Global Round : 12 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 39.211575\n",
      "| Global Round : 12 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 43.491634\n",
      "| Global Round : 12 | Local Epoch : 9 | [17250/18116 (106%)]\tBatch Loss: 42.903275\n",
      "Client 0: accuracy loss: 97.34 | fairness loss 1.47 | RD = 0.43 = |10/592-631/1421| \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [01:54<01:05,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1: accuracy loss: 57.69 | fairness loss 1.65 | RD = 0.38 = |9/421-334/823| \n",
      " \n",
      "Avg Training Stats after 13 global rounds:\n",
      "Training loss: 47.57 | Training accuracy: 81.34% | Training RD: 0.41\n",
      "\n",
      " | Global Training Round : 14 |\n",
      "\n",
      "| Global Round : 13 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 265.226837\n",
      "| Global Round : 13 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 44.689098\n",
      "| Global Round : 13 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 205.875763\n",
      "| Global Round : 13 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 44.242203\n",
      "| Global Round : 13 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 250.528305\n",
      "| Global Round : 13 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 44.122223\n",
      "| Global Round : 13 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 278.961304\n",
      "| Global Round : 13 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 44.239784\n",
      "| Global Round : 13 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 307.487000\n",
      "| Global Round : 13 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 41.264118\n",
      "| Global Round : 13 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 234.483627\n",
      "| Global Round : 13 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 48.395359\n",
      "| Global Round : 13 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 246.797318\n",
      "| Global Round : 13 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 47.999638\n",
      "| Global Round : 13 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 262.025818\n",
      "| Global Round : 13 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 50.235001\n",
      "| Global Round : 13 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 287.010681\n",
      "| Global Round : 13 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 42.202629\n",
      "| Global Round : 13 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 343.796173\n",
      "| Global Round : 13 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 44.379047\n",
      "| Global Round : 13 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 313.132446\n",
      "| Global Round : 13 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 47.411015\n",
      "| Global Round : 13 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 32.900021\n",
      "| Global Round : 13 | Local Epoch : 0 | [17250/18116 (106%)]\tBatch Loss: 40.299641\n",
      "| Global Round : 13 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 325.626312\n",
      "| Global Round : 13 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 33.192287\n",
      "| Global Round : 13 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 37.769791\n",
      "| Global Round : 13 | Local Epoch : 1 | [17250/18116 (106%)]\tBatch Loss: 48.038612\n",
      "| Global Round : 13 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 399.353821\n",
      "| Global Round : 13 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 47.944763\n",
      "| Global Round : 13 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 50.240349\n",
      "| Global Round : 13 | Local Epoch : 2 | [17250/18116 (106%)]\tBatch Loss: 42.681648\n",
      "| Global Round : 13 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 279.977509\n",
      "| Global Round : 13 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 34.866734\n",
      "| Global Round : 13 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 28.919960\n",
      "| Global Round : 13 | Local Epoch : 3 | [17250/18116 (106%)]\tBatch Loss: 32.419174\n",
      "| Global Round : 13 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 337.969543\n",
      "| Global Round : 13 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 40.643185\n",
      "| Global Round : 13 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 42.901703\n",
      "| Global Round : 13 | Local Epoch : 4 | [17250/18116 (106%)]\tBatch Loss: 42.473686\n",
      "| Global Round : 13 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 252.187225\n",
      "| Global Round : 13 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 40.813721\n",
      "| Global Round : 13 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 30.932791\n",
      "| Global Round : 13 | Local Epoch : 5 | [17250/18116 (106%)]\tBatch Loss: 33.630417\n",
      "| Global Round : 13 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 310.637909\n",
      "| Global Round : 13 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 41.845852\n",
      "| Global Round : 13 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 34.900196\n",
      "| Global Round : 13 | Local Epoch : 6 | [17250/18116 (106%)]\tBatch Loss: 35.484447\n",
      "| Global Round : 13 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 278.793945\n",
      "| Global Round : 13 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 35.124538\n",
      "| Global Round : 13 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 48.233364\n",
      "| Global Round : 13 | Local Epoch : 7 | [17250/18116 (106%)]\tBatch Loss: 40.334690\n",
      "| Global Round : 13 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 345.942017\n",
      "| Global Round : 13 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 41.530926\n",
      "| Global Round : 13 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 44.780743\n",
      "| Global Round : 13 | Local Epoch : 8 | [17250/18116 (106%)]\tBatch Loss: 40.291759\n",
      "| Global Round : 13 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 309.475006\n",
      "| Global Round : 13 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 38.936077\n",
      "| Global Round : 13 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 35.266647\n",
      "| Global Round : 13 | Local Epoch : 9 | [17250/18116 (106%)]\tBatch Loss: 38.765747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [02:04<00:56,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 97.74 | fairness loss 1.43 | RD = 0.45 = |15/592-669/1421| \n",
      "Client 1: accuracy loss: 57.87 | fairness loss 1.60 | RD = 0.41 = |9/421-359/823| \n",
      " \n",
      "Avg Training Stats after 14 global rounds:\n",
      "Training loss: 47.51 | Training accuracy: 80.70% | Training RD: 0.43\n",
      "\n",
      " | Global Training Round : 15 |\n",
      "\n",
      "| Global Round : 14 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 266.281738\n",
      "| Global Round : 14 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 45.963379\n",
      "| Global Round : 14 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 275.120422\n",
      "| Global Round : 14 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 31.203827\n",
      "| Global Round : 14 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 285.076813\n",
      "| Global Round : 14 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 52.684902\n",
      "| Global Round : 14 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 235.212540\n",
      "| Global Round : 14 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 40.758327\n",
      "| Global Round : 14 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 319.204651\n",
      "| Global Round : 14 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 48.875996\n",
      "| Global Round : 14 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 254.112686\n",
      "| Global Round : 14 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 53.145885\n",
      "| Global Round : 14 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 260.631775\n",
      "| Global Round : 14 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 43.313026\n",
      "| Global Round : 14 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 242.447647\n",
      "| Global Round : 14 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 50.904148\n",
      "| Global Round : 14 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 263.819092\n",
      "| Global Round : 14 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 44.232403\n",
      "| Global Round : 14 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 263.376495\n",
      "| Global Round : 14 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 42.903809\n",
      "| Global Round : 14 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 292.086365\n",
      "| Global Round : 14 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 55.455402\n",
      "| Global Round : 14 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 45.920536\n",
      "| Global Round : 14 | Local Epoch : 0 | [19200/18116 (106%)]\tBatch Loss: 38.951694\n",
      "| Global Round : 14 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 275.364594\n",
      "| Global Round : 14 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 37.574459\n",
      "| Global Round : 14 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 45.073528\n",
      "| Global Round : 14 | Local Epoch : 1 | [19200/18116 (106%)]\tBatch Loss: 39.276024\n",
      "| Global Round : 14 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 337.209991\n",
      "| Global Round : 14 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 47.565357\n",
      "| Global Round : 14 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 42.814533\n",
      "| Global Round : 14 | Local Epoch : 2 | [19200/18116 (106%)]\tBatch Loss: 33.347874\n",
      "| Global Round : 14 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 291.736725\n",
      "| Global Round : 14 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 76.193077\n",
      "| Global Round : 14 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 35.423424\n",
      "| Global Round : 14 | Local Epoch : 3 | [19200/18116 (106%)]\tBatch Loss: 48.077850\n",
      "| Global Round : 14 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 336.361786\n",
      "| Global Round : 14 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 63.513706\n",
      "| Global Round : 14 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 27.394135\n",
      "| Global Round : 14 | Local Epoch : 4 | [19200/18116 (106%)]\tBatch Loss: 46.464508\n",
      "| Global Round : 14 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 277.486725\n",
      "| Global Round : 14 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 41.580444\n",
      "| Global Round : 14 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 47.186607\n",
      "| Global Round : 14 | Local Epoch : 5 | [19200/18116 (106%)]\tBatch Loss: 58.104622\n",
      "| Global Round : 14 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 241.259186\n",
      "| Global Round : 14 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 33.346466\n",
      "| Global Round : 14 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 38.833298\n",
      "| Global Round : 14 | Local Epoch : 6 | [19200/18116 (106%)]\tBatch Loss: 37.232994\n",
      "| Global Round : 14 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 382.318451\n",
      "| Global Round : 14 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 41.955528\n",
      "| Global Round : 14 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 42.888107\n",
      "| Global Round : 14 | Local Epoch : 7 | [19200/18116 (106%)]\tBatch Loss: 43.533588\n",
      "| Global Round : 14 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 282.583313\n",
      "| Global Round : 14 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 39.769302\n",
      "| Global Round : 14 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 41.441689\n",
      "| Global Round : 14 | Local Epoch : 8 | [19200/18116 (106%)]\tBatch Loss: 48.724052\n",
      "| Global Round : 14 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 335.767975\n",
      "| Global Round : 14 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 44.869823\n",
      "| Global Round : 14 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 47.806271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [02:13<00:46,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 14 | Local Epoch : 9 | [19200/18116 (106%)]\tBatch Loss: 58.226120\n",
      "Client 0: accuracy loss: 96.74 | fairness loss 1.49 | RD = 0.39 = |10/592-578/1421| \n",
      "Client 1: accuracy loss: 57.42 | fairness loss 1.66 | RD = 0.36 = |9/421-310/823| \n",
      " \n",
      "Avg Training Stats after 15 global rounds:\n",
      "Training loss: 47.46 | Training accuracy: 82.38% | Training RD: 0.38\n",
      "\n",
      " | Global Training Round : 16 |\n",
      "\n",
      "| Global Round : 15 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 280.238953\n",
      "| Global Round : 15 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 45.857357\n",
      "| Global Round : 15 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 273.899445\n",
      "| Global Round : 15 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 31.082336\n",
      "| Global Round : 15 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 284.766632\n",
      "| Global Round : 15 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 52.766304\n",
      "| Global Round : 15 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 234.794983\n",
      "| Global Round : 15 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 40.715046\n",
      "| Global Round : 15 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 319.150146\n",
      "| Global Round : 15 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 48.882420\n",
      "| Global Round : 15 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 253.989960\n",
      "| Global Round : 15 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 53.069546\n",
      "| Global Round : 15 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 260.608154\n",
      "| Global Round : 15 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 43.382267\n",
      "| Global Round : 15 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 242.252182\n",
      "| Global Round : 15 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 50.990936\n",
      "| Global Round : 15 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 263.252625\n",
      "| Global Round : 15 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 44.209885\n",
      "| Global Round : 15 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 263.048950\n",
      "| Global Round : 15 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 42.882027\n",
      "| Global Round : 15 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 307.281494\n",
      "| Global Round : 15 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 55.287186\n",
      "| Global Round : 15 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 45.988224\n",
      "| Global Round : 15 | Local Epoch : 0 | [19200/18116 (106%)]\tBatch Loss: 39.032658\n",
      "| Global Round : 15 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 274.784332\n",
      "| Global Round : 15 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 37.545506\n",
      "| Global Round : 15 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 44.951836\n",
      "| Global Round : 15 | Local Epoch : 1 | [19200/18116 (106%)]\tBatch Loss: 39.278000\n",
      "| Global Round : 15 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 335.749084\n",
      "| Global Round : 15 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 47.653015\n",
      "| Global Round : 15 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 42.810329\n",
      "| Global Round : 15 | Local Epoch : 2 | [19200/18116 (106%)]\tBatch Loss: 33.257580\n",
      "| Global Round : 15 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 290.976471\n",
      "| Global Round : 15 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 76.066071\n",
      "| Global Round : 15 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 35.400570\n",
      "| Global Round : 15 | Local Epoch : 3 | [19200/18116 (106%)]\tBatch Loss: 48.062073\n",
      "| Global Round : 15 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 336.156708\n",
      "| Global Round : 15 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 63.561699\n",
      "| Global Round : 15 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 27.384079\n",
      "| Global Round : 15 | Local Epoch : 4 | [19200/18116 (106%)]\tBatch Loss: 46.497139\n",
      "| Global Round : 15 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 277.266754\n",
      "| Global Round : 15 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 41.571728\n",
      "| Global Round : 15 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 47.080517\n",
      "| Global Round : 15 | Local Epoch : 5 | [19200/18116 (106%)]\tBatch Loss: 57.905632\n",
      "| Global Round : 15 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 241.209808\n",
      "| Global Round : 15 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 33.276787\n",
      "| Global Round : 15 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 38.827068\n",
      "| Global Round : 15 | Local Epoch : 6 | [19200/18116 (106%)]\tBatch Loss: 37.219234\n",
      "| Global Round : 15 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 381.837708\n",
      "| Global Round : 15 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 41.930981\n",
      "| Global Round : 15 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 42.884605\n",
      "| Global Round : 15 | Local Epoch : 7 | [19200/18116 (106%)]\tBatch Loss: 43.534801\n",
      "| Global Round : 15 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 282.462097\n",
      "| Global Round : 15 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 39.798264\n",
      "| Global Round : 15 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 41.417786\n",
      "| Global Round : 15 | Local Epoch : 8 | [19200/18116 (106%)]\tBatch Loss: 48.691032\n",
      "| Global Round : 15 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 335.520477\n",
      "| Global Round : 15 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 44.862919\n",
      "| Global Round : 15 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 47.746052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [02:21<00:36,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 15 | Local Epoch : 9 | [19200/18116 (106%)]\tBatch Loss: 58.236214\n",
      "Client 0: accuracy loss: 96.61 | fairness loss 1.51 | RD = 0.39 = |10/592-574/1421| \n",
      "Client 1: accuracy loss: 57.37 | fairness loss 1.67 | RD = 0.35 = |9/421-307/823| \n",
      " \n",
      "Avg Training Stats after 16 global rounds:\n",
      "Training loss: 47.42 | Training accuracy: 82.42% | Training RD: 0.37\n",
      "\n",
      " | Global Training Round : 17 |\n",
      "\n",
      "| Global Round : 16 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 257.541779\n",
      "| Global Round : 16 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 31.427713\n",
      "| Global Round : 16 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 315.984131\n",
      "| Global Round : 16 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 35.733295\n",
      "| Global Round : 16 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 298.845825\n",
      "| Global Round : 16 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 43.780006\n",
      "| Global Round : 16 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 345.733002\n",
      "| Global Round : 16 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 48.543785\n",
      "| Global Round : 16 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 283.403564\n",
      "| Global Round : 16 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 42.165703\n",
      "| Global Round : 16 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 266.913574\n",
      "| Global Round : 16 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 43.466331\n",
      "| Global Round : 16 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 218.344925\n",
      "| Global Round : 16 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 41.476967\n",
      "| Global Round : 16 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 279.660217\n",
      "| Global Round : 16 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 58.478703\n",
      "| Global Round : 16 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 283.764313\n",
      "| Global Round : 16 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 37.043018\n",
      "| Global Round : 16 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 293.796692\n",
      "| Global Round : 16 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 42.960335\n",
      "| Global Round : 16 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 300.678497\n",
      "| Global Round : 16 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 50.982315\n",
      "| Global Round : 16 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 47.235298\n",
      "| Global Round : 16 | Local Epoch : 0 | [17400/18116 (106%)]\tBatch Loss: 34.361271\n",
      "| Global Round : 16 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 277.430695\n",
      "| Global Round : 16 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 41.294224\n",
      "| Global Round : 16 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 45.086475\n",
      "| Global Round : 16 | Local Epoch : 1 | [17400/18116 (106%)]\tBatch Loss: 28.429893\n",
      "| Global Round : 16 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 380.054901\n",
      "| Global Round : 16 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 45.972702\n",
      "| Global Round : 16 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 39.766026\n",
      "| Global Round : 16 | Local Epoch : 2 | [17400/18116 (106%)]\tBatch Loss: 30.208321\n",
      "| Global Round : 16 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 289.731781\n",
      "| Global Round : 16 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 38.258335\n",
      "| Global Round : 16 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 34.874943\n",
      "| Global Round : 16 | Local Epoch : 3 | [17400/18116 (106%)]\tBatch Loss: 31.740902\n",
      "| Global Round : 16 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 318.147705\n",
      "| Global Round : 16 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 53.472893\n",
      "| Global Round : 16 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 37.875515\n",
      "| Global Round : 16 | Local Epoch : 4 | [17400/18116 (106%)]\tBatch Loss: 45.126915\n",
      "| Global Round : 16 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 285.232666\n",
      "| Global Round : 16 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 37.969166\n",
      "| Global Round : 16 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 47.277382\n",
      "| Global Round : 16 | Local Epoch : 5 | [17400/18116 (106%)]\tBatch Loss: 37.057953\n",
      "| Global Round : 16 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 290.018127\n",
      "| Global Round : 16 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 43.456940\n",
      "| Global Round : 16 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 38.028481\n",
      "| Global Round : 16 | Local Epoch : 6 | [17400/18116 (106%)]\tBatch Loss: 31.716877\n",
      "| Global Round : 16 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 304.585144\n",
      "| Global Round : 16 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 38.686089\n",
      "| Global Round : 16 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 29.539268\n",
      "| Global Round : 16 | Local Epoch : 7 | [17400/18116 (106%)]\tBatch Loss: 32.553238\n",
      "| Global Round : 16 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 331.689026\n",
      "| Global Round : 16 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 47.862511\n",
      "| Global Round : 16 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 39.232220\n",
      "| Global Round : 16 | Local Epoch : 8 | [17400/18116 (106%)]\tBatch Loss: 35.120155\n",
      "| Global Round : 16 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 363.252655\n",
      "| Global Round : 16 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 36.102493\n",
      "| Global Round : 16 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 34.286175\n",
      "| Global Round : 16 | Local Epoch : 9 | [17400/18116 (106%)]\tBatch Loss: 29.542250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [02:31<00:27,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 96.37 | fairness loss 1.52 | RD = 0.37 = |8/592-544/1421| \n",
      "Client 1: accuracy loss: 57.29 | fairness loss 1.68 | RD = 0.34 = |9/421-294/823| \n",
      " \n",
      "Avg Training Stats after 17 global rounds:\n",
      "Training loss: 47.35 | Training accuracy: 82.78% | Training RD: 0.36\n",
      "\n",
      " | Global Training Round : 18 |\n",
      "\n",
      "| Global Round : 17 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 267.701050\n",
      "| Global Round : 17 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 44.387108\n",
      "| Global Round : 17 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 258.620605\n",
      "| Global Round : 17 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 43.897266\n",
      "| Global Round : 17 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 224.155823\n",
      "| Global Round : 17 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 47.180847\n",
      "| Global Round : 17 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 311.256897\n",
      "| Global Round : 17 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 45.945496\n",
      "| Global Round : 17 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 298.530640\n",
      "| Global Round : 17 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 53.283829\n",
      "| Global Round : 17 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 252.360855\n",
      "| Global Round : 17 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 41.886887\n",
      "| Global Round : 17 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 318.380035\n",
      "| Global Round : 17 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 37.642399\n",
      "| Global Round : 17 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 293.492828\n",
      "| Global Round : 17 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 36.560059\n",
      "| Global Round : 17 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 252.614227\n",
      "| Global Round : 17 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 52.767056\n",
      "| Global Round : 17 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 305.491943\n",
      "| Global Round : 17 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 35.644306\n",
      "| Global Round : 17 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 291.679077\n",
      "| Global Round : 17 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 44.541218\n",
      "| Global Round : 17 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 40.828724\n",
      "| Global Round : 17 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 287.842804\n",
      "| Global Round : 17 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 47.529995\n",
      "| Global Round : 17 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 42.575180\n",
      "| Global Round : 17 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 358.178314\n",
      "| Global Round : 17 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 50.816242\n",
      "| Global Round : 17 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 28.025129\n",
      "| Global Round : 17 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 283.879883\n",
      "| Global Round : 17 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 45.722271\n",
      "| Global Round : 17 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 56.245979\n",
      "| Global Round : 17 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 348.843719\n",
      "| Global Round : 17 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 44.363926\n",
      "| Global Round : 17 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 35.192913\n",
      "| Global Round : 17 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 308.478729\n",
      "| Global Round : 17 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 36.754818\n",
      "| Global Round : 17 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 32.578453\n",
      "| Global Round : 17 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 352.049530\n",
      "| Global Round : 17 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 46.205284\n",
      "| Global Round : 17 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 50.239380\n",
      "| Global Round : 17 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 346.161316\n",
      "| Global Round : 17 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 38.582775\n",
      "| Global Round : 17 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 38.840893\n",
      "| Global Round : 17 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 390.356659\n",
      "| Global Round : 17 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 39.513012\n",
      "| Global Round : 17 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 36.837757\n",
      "| Global Round : 17 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 386.304688\n",
      "| Global Round : 17 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 39.725132\n",
      "| Global Round : 17 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 38.181774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [02:41<00:18,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 97.15 | fairness loss 1.45 | RD = 0.42 = |14/592-637/1421| \n",
      "Client 1: accuracy loss: 57.57 | fairness loss 1.60 | RD = 0.39 = |10/421-342/823| \n",
      " \n",
      "Avg Training Stats after 18 global rounds:\n",
      "Training loss: 47.27 | Training accuracy: 81.53% | Training RD: 0.41\n",
      "\n",
      " | Global Training Round : 19 |\n",
      "\n",
      "| Global Round : 18 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 267.431000\n",
      "| Global Round : 18 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 40.636414\n",
      "| Global Round : 18 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 246.563049\n",
      "| Global Round : 18 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 38.450420\n",
      "| Global Round : 18 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 261.883698\n",
      "| Global Round : 18 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 41.939892\n",
      "| Global Round : 18 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 285.680481\n",
      "| Global Round : 18 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 43.233910\n",
      "| Global Round : 18 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 264.642273\n",
      "| Global Round : 18 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 49.852058\n",
      "| Global Round : 18 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 246.854218\n",
      "| Global Round : 18 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 50.830200\n",
      "| Global Round : 18 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 270.188751\n",
      "| Global Round : 18 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 50.430775\n",
      "| Global Round : 18 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 242.448532\n",
      "| Global Round : 18 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 49.695751\n",
      "| Global Round : 18 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 226.853348\n",
      "| Global Round : 18 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 46.664700\n",
      "| Global Round : 18 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 255.500565\n",
      "| Global Round : 18 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 43.407654\n",
      "| Global Round : 18 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 271.057953\n",
      "| Global Round : 18 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 49.369801\n",
      "| Global Round : 18 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 36.750229\n",
      "| Global Round : 18 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 298.612671\n",
      "| Global Round : 18 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 41.295128\n",
      "| Global Round : 18 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 56.971214\n",
      "| Global Round : 18 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 345.189911\n",
      "| Global Round : 18 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 29.816584\n",
      "| Global Round : 18 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 35.004566\n",
      "| Global Round : 18 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 350.458893\n",
      "| Global Round : 18 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 42.286034\n",
      "| Global Round : 18 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 50.294422\n",
      "| Global Round : 18 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 306.919098\n",
      "| Global Round : 18 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 45.463329\n",
      "| Global Round : 18 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 37.673595\n",
      "| Global Round : 18 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 269.180695\n",
      "| Global Round : 18 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 48.853687\n",
      "| Global Round : 18 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 38.812981\n",
      "| Global Round : 18 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 361.372986\n",
      "| Global Round : 18 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 31.846815\n",
      "| Global Round : 18 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 55.478340\n",
      "| Global Round : 18 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 356.763367\n",
      "| Global Round : 18 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 66.544907\n",
      "| Global Round : 18 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 33.303833\n",
      "| Global Round : 18 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 344.336700\n",
      "| Global Round : 18 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 37.713802\n",
      "| Global Round : 18 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 56.817345\n",
      "| Global Round : 18 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 330.037720\n",
      "| Global Round : 18 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 38.892036\n",
      "| Global Round : 18 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 37.768368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [02:50<00:09,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 96.47 | fairness loss 1.44 | RD = 0.38 = |14/592-575/1421| \n",
      "Client 1: accuracy loss: 57.35 | fairness loss 1.59 | RD = 0.36 = |10/421-317/823| \n",
      " \n",
      "Avg Training Stats after 19 global rounds:\n",
      "Training loss: 47.23 | Training accuracy: 82.49% | Training RD: 0.37\n",
      "\n",
      " | Global Training Round : 20 |\n",
      "\n",
      "| Global Round : 19 | Local Epoch : 0 | [0/11188 (0%)]\tBatch Loss: 260.192902\n",
      "| Global Round : 19 | Local Epoch : 0 | [6400/11188 (57%)]\tBatch Loss: 39.220600\n",
      "| Global Round : 19 | Local Epoch : 1 | [0/11188 (0%)]\tBatch Loss: 221.713791\n",
      "| Global Round : 19 | Local Epoch : 1 | [6400/11188 (57%)]\tBatch Loss: 33.998917\n",
      "| Global Round : 19 | Local Epoch : 2 | [0/11188 (0%)]\tBatch Loss: 266.978119\n",
      "| Global Round : 19 | Local Epoch : 2 | [6400/11188 (57%)]\tBatch Loss: 40.089378\n",
      "| Global Round : 19 | Local Epoch : 3 | [0/11188 (0%)]\tBatch Loss: 289.233948\n",
      "| Global Round : 19 | Local Epoch : 3 | [6400/11188 (57%)]\tBatch Loss: 42.057045\n",
      "| Global Round : 19 | Local Epoch : 4 | [0/11188 (0%)]\tBatch Loss: 267.101562\n",
      "| Global Round : 19 | Local Epoch : 4 | [6400/11188 (57%)]\tBatch Loss: 56.352512\n",
      "| Global Round : 19 | Local Epoch : 5 | [0/11188 (0%)]\tBatch Loss: 269.527863\n",
      "| Global Round : 19 | Local Epoch : 5 | [6400/11188 (57%)]\tBatch Loss: 53.270958\n",
      "| Global Round : 19 | Local Epoch : 6 | [0/11188 (0%)]\tBatch Loss: 297.724152\n",
      "| Global Round : 19 | Local Epoch : 6 | [6400/11188 (57%)]\tBatch Loss: 40.429203\n",
      "| Global Round : 19 | Local Epoch : 7 | [0/11188 (0%)]\tBatch Loss: 233.985321\n",
      "| Global Round : 19 | Local Epoch : 7 | [6400/11188 (57%)]\tBatch Loss: 45.254498\n",
      "| Global Round : 19 | Local Epoch : 8 | [0/11188 (0%)]\tBatch Loss: 235.327576\n",
      "| Global Round : 19 | Local Epoch : 8 | [6400/11188 (57%)]\tBatch Loss: 49.268612\n",
      "| Global Round : 19 | Local Epoch : 9 | [0/11188 (0%)]\tBatch Loss: 238.923798\n",
      "| Global Round : 19 | Local Epoch : 9 | [6400/11188 (57%)]\tBatch Loss: 48.373444\n",
      "| Global Round : 19 | Local Epoch : 0 | [0/18116 (0%)]\tBatch Loss: 262.783203\n",
      "| Global Round : 19 | Local Epoch : 0 | [6400/18116 (35%)]\tBatch Loss: 32.201557\n",
      "| Global Round : 19 | Local Epoch : 0 | [12800/18116 (70%)]\tBatch Loss: 50.069294\n",
      "| Global Round : 19 | Local Epoch : 1 | [0/18116 (0%)]\tBatch Loss: 288.583008\n",
      "| Global Round : 19 | Local Epoch : 1 | [6400/18116 (35%)]\tBatch Loss: 31.840460\n",
      "| Global Round : 19 | Local Epoch : 1 | [12800/18116 (70%)]\tBatch Loss: 43.160095\n",
      "| Global Round : 19 | Local Epoch : 2 | [0/18116 (0%)]\tBatch Loss: 363.442841\n",
      "| Global Round : 19 | Local Epoch : 2 | [6400/18116 (35%)]\tBatch Loss: 30.870941\n",
      "| Global Round : 19 | Local Epoch : 2 | [12800/18116 (70%)]\tBatch Loss: 58.738964\n",
      "| Global Round : 19 | Local Epoch : 3 | [0/18116 (0%)]\tBatch Loss: 355.172119\n",
      "| Global Round : 19 | Local Epoch : 3 | [6400/18116 (35%)]\tBatch Loss: 47.419781\n",
      "| Global Round : 19 | Local Epoch : 3 | [12800/18116 (70%)]\tBatch Loss: 41.991146\n",
      "| Global Round : 19 | Local Epoch : 4 | [0/18116 (0%)]\tBatch Loss: 296.715210\n",
      "| Global Round : 19 | Local Epoch : 4 | [6400/18116 (35%)]\tBatch Loss: 35.901978\n",
      "| Global Round : 19 | Local Epoch : 4 | [12800/18116 (70%)]\tBatch Loss: 38.251320\n",
      "| Global Round : 19 | Local Epoch : 5 | [0/18116 (0%)]\tBatch Loss: 263.576355\n",
      "| Global Round : 19 | Local Epoch : 5 | [6400/18116 (35%)]\tBatch Loss: 38.832993\n",
      "| Global Round : 19 | Local Epoch : 5 | [12800/18116 (70%)]\tBatch Loss: 31.896816\n",
      "| Global Round : 19 | Local Epoch : 6 | [0/18116 (0%)]\tBatch Loss: 363.829651\n",
      "| Global Round : 19 | Local Epoch : 6 | [6400/18116 (35%)]\tBatch Loss: 32.053894\n",
      "| Global Round : 19 | Local Epoch : 6 | [12800/18116 (70%)]\tBatch Loss: 41.572269\n",
      "| Global Round : 19 | Local Epoch : 7 | [0/18116 (0%)]\tBatch Loss: 369.918579\n",
      "| Global Round : 19 | Local Epoch : 7 | [6400/18116 (35%)]\tBatch Loss: 48.032448\n",
      "| Global Round : 19 | Local Epoch : 7 | [12800/18116 (70%)]\tBatch Loss: 38.908653\n",
      "| Global Round : 19 | Local Epoch : 8 | [0/18116 (0%)]\tBatch Loss: 334.048462\n",
      "| Global Round : 19 | Local Epoch : 8 | [6400/18116 (35%)]\tBatch Loss: 36.992672\n",
      "| Global Round : 19 | Local Epoch : 8 | [12800/18116 (70%)]\tBatch Loss: 52.305050\n",
      "| Global Round : 19 | Local Epoch : 9 | [0/18116 (0%)]\tBatch Loss: 327.812561\n",
      "| Global Round : 19 | Local Epoch : 9 | [6400/18116 (35%)]\tBatch Loss: 44.113029\n",
      "| Global Round : 19 | Local Epoch : 9 | [12800/18116 (70%)]\tBatch Loss: 42.500523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:00<00:00,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: accuracy loss: 95.98 | fairness loss 1.49 | RD = 0.36 = |13/592-536/1421| \n",
      "Client 1: accuracy loss: 57.10 | fairness loss 1.64 | RD = 0.33 = |10/421-288/823| \n",
      " \n",
      "Avg Training Stats after 20 global rounds:\n",
      "Training loss: 47.20 | Training accuracy: 83.05% | Training RD: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Results after 20 global rounds of training:\n",
      "|---- Avg Train Accuracy: 83.05%\n",
      "|---- Test Accuracy: 84.31%\n",
      "|---- Test RD: 0.27\n",
      "\n",
      " Total Run Time: 180.6578 sec\n"
     ]
    }
   ],
   "source": [
    "train(logReg(num_features=NUM_FEATURES, num_classes=2), \n",
    "      option = \"FairBatch\", optimizer = 'sgd', learning_rate = 0.01, \n",
    "      num_rounds = 20, local_epochs = 10, alpha = 0.005)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
